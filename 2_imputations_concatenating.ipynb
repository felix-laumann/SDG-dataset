{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing missing values\n",
    "\n",
    "We work with the data set how it is present now and apply a common machine learning methods to compute the imputations for missing values: \n",
    "\n",
    "The **weighted k nearest neighbour (w-kNN)** algorithm, which imputes missing values with weights equal to the inverse Euclidean distance. \n",
    "\n",
    "**Assumptions:** we believe the values missing lie in between the boundaries of the highest and lowest value present in the data set. This might work well for most, but it could also be that the missing values are outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on `countries`\n",
    "\n",
    "We want to **remind** ourselves that our list `groupings` does not only contain countries, it also contains groups of countries like continents, economic zones, etc. and islands which belong to certain countries, but could somehow be very different as e.g. territories. We save all these entries in a new list `countries`. \n",
    "\n",
    "Furthermore, some sub-indicators are of ordinal type, i.e. they are defined as 'number of countries which...'. For all countries, we have here either a 1 or a 0 for 'yes' or 'no', respectively. For all other groupings, we have there most likely a number larger than 1. This could be tricky for our imputations later, because these are based on the similarity of two groupings and these similarities could be strong between, say, France and the World Trade Organisation (WTO). If the WTO had a missing value for an ordinal sub-indicator, the imputation would most likely be very similar to the one of France, so 1 or 0. But this is unrealistic, and all other countries being member of the WTO and behave almost as similar as France, would make the imputation just closer to 1 and not larger than 1.\n",
    "\n",
    "Therefore, we focus on `countries` only from hereon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading original and standardised data set\n",
    "dict_all = pickle.load(open('utils/data/dict_all_wb.pkl', 'rb'))\n",
    "dict_all_std = pickle.load(open('utils/data/dict_all_wb_std.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original values: \n",
      "1990          NaN\n",
      "1991          NaN\n",
      "1992          NaN\n",
      "1993          NaN\n",
      "1994          NaN\n",
      "1995          NaN\n",
      "1996          NaN\n",
      "1997    64.083333\n",
      "1998          NaN\n",
      "1999          NaN\n",
      "2000          NaN\n",
      "2001          NaN\n",
      "2002    56.125000\n",
      "2003          NaN\n",
      "2004          NaN\n",
      "2005          NaN\n",
      "2006          NaN\n",
      "2007    51.783333\n",
      "2008          NaN\n",
      "2009          NaN\n",
      "2010          NaN\n",
      "2011          NaN\n",
      "2012    50.016667\n",
      "2013          NaN\n",
      "2014          NaN\n",
      "2015          NaN\n",
      "2016          NaN\n",
      "2017          NaN\n",
      "2018          NaN\n",
      "2019          NaN\n",
      "Name: ER.H2O.FWTL.ZS, dtype: float64\n",
      "--------\n",
      "Standardised values: \n",
      "1990         NaN\n",
      "1991         NaN\n",
      "1992         NaN\n",
      "1993         NaN\n",
      "1994         NaN\n",
      "1995         NaN\n",
      "1996         NaN\n",
      "1997    1.580306\n",
      "1998         NaN\n",
      "1999         NaN\n",
      "2000         NaN\n",
      "2001         NaN\n",
      "2002    0.114715\n",
      "2003         NaN\n",
      "2004         NaN\n",
      "2005         NaN\n",
      "2006         NaN\n",
      "2007   -0.684838\n",
      "2008         NaN\n",
      "2009         NaN\n",
      "2010         NaN\n",
      "2011         NaN\n",
      "2012   -1.010183\n",
      "2013         NaN\n",
      "2014         NaN\n",
      "2015         NaN\n",
      "2016         NaN\n",
      "2017         NaN\n",
      "2018         NaN\n",
      "2019         NaN\n",
      "Name: ER.H2O.FWTL.ZS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "print('Original values: ')\n",
    "print(dict_all['Belgium'].loc['ER.H2O.FWTL.ZS'])\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Standardised values: ')\n",
    "print(dict_all_std['Belgium'].loc['ER.H2O.FWTL.ZS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the total number of values we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "844553\n"
     ]
    }
   ],
   "source": [
    "# number of values\n",
    "s = 0\n",
    "for country in dict_all_std.keys():\n",
    "    s += np.sum(dict_all_std[country].count())\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we open the `csv` file in a GUI and delete the groupings which are *not* countries or part of countries. We call these non-country groupings and examples are North America, Western Asia, Least Developed Countries (LDC), Land Locked Developing Countries (LLDC), Small Island Developing States (SIDS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Afghanistan',\n",
       " 'Albania',\n",
       " 'Algeria',\n",
       " 'Angola',\n",
       " 'Antigua and Barbuda',\n",
       " 'Argentina',\n",
       " 'Armenia',\n",
       " 'Australia',\n",
       " 'Austria',\n",
       " 'Azerbaijan',\n",
       " 'Bahamas, The',\n",
       " 'Bahrain',\n",
       " 'Bangladesh',\n",
       " 'Barbados',\n",
       " 'Belarus',\n",
       " 'Belgium',\n",
       " 'Belize',\n",
       " 'Benin',\n",
       " 'Bhutan',\n",
       " 'Bolivia',\n",
       " 'Bosnia and Herzegovina',\n",
       " 'Botswana',\n",
       " 'Brazil',\n",
       " 'Brunei Darussalam',\n",
       " 'Bulgaria',\n",
       " 'Burkina Faso',\n",
       " 'Burundi',\n",
       " 'Cambodia',\n",
       " 'Cameroon',\n",
       " 'Canada',\n",
       " 'Central African Republic',\n",
       " 'Chad',\n",
       " 'Chile',\n",
       " 'China',\n",
       " 'Colombia',\n",
       " 'Comoros',\n",
       " 'Congo, Dem. Rep.',\n",
       " 'Congo, Rep.',\n",
       " 'Costa Rica',\n",
       " \"Cote d'Ivoire\",\n",
       " 'Croatia',\n",
       " 'Cuba',\n",
       " 'Cyprus',\n",
       " 'Czech Republic',\n",
       " 'Denmark',\n",
       " 'Djibouti',\n",
       " 'Dominica',\n",
       " 'Dominican Republic',\n",
       " 'Ecuador',\n",
       " 'Egypt, Arab Rep.',\n",
       " 'El Salvador',\n",
       " 'Equatorial Guinea',\n",
       " 'Eritrea',\n",
       " 'Estonia',\n",
       " 'Ethiopia',\n",
       " 'Fiji',\n",
       " 'Finland',\n",
       " 'France',\n",
       " 'Gabon',\n",
       " 'Gambia, The',\n",
       " 'Georgia',\n",
       " 'Germany',\n",
       " 'Ghana',\n",
       " 'Greece',\n",
       " 'Greenland',\n",
       " 'Grenada',\n",
       " 'Guatemala',\n",
       " 'Guinea',\n",
       " 'Guinea-Bissau',\n",
       " 'Guyana',\n",
       " 'Haiti',\n",
       " 'Honduras',\n",
       " 'Hungary',\n",
       " 'Iceland',\n",
       " 'India',\n",
       " 'Indonesia',\n",
       " 'Iran, Islamic Rep.',\n",
       " 'Iraq',\n",
       " 'Ireland',\n",
       " 'Israel',\n",
       " 'Italy',\n",
       " 'Jamaica',\n",
       " 'Japan',\n",
       " 'Jordan',\n",
       " 'Kazakhstan',\n",
       " 'Kenya',\n",
       " 'Kiribati',\n",
       " \"Korea, Dem. People's Rep.\",\n",
       " 'Kuwait',\n",
       " 'Kyrgyz Republic',\n",
       " 'Lao PDR',\n",
       " 'Latvia',\n",
       " 'Lebanon',\n",
       " 'Lesotho',\n",
       " 'Liberia',\n",
       " 'Libya',\n",
       " 'Liechtenstein',\n",
       " 'Lithuania',\n",
       " 'Luxembourg',\n",
       " 'Madagascar',\n",
       " 'Malawi',\n",
       " 'Malaysia',\n",
       " 'Maldives',\n",
       " 'Mali',\n",
       " 'Malta',\n",
       " 'Mauritania',\n",
       " 'Mauritius',\n",
       " 'Mexico',\n",
       " 'Micronesia, Fed. Sts.',\n",
       " 'Moldova',\n",
       " 'Mongolia',\n",
       " 'Montenegro',\n",
       " 'Morocco',\n",
       " 'Mozambique',\n",
       " 'Myanmar',\n",
       " 'Namibia',\n",
       " 'Nepal',\n",
       " 'Netherlands',\n",
       " 'New Zealand',\n",
       " 'Nicaragua',\n",
       " 'Niger',\n",
       " 'Nigeria',\n",
       " 'Norway',\n",
       " 'Oman',\n",
       " 'Pakistan',\n",
       " 'Palau',\n",
       " 'Panama',\n",
       " 'Papua New Guinea',\n",
       " 'Paraguay',\n",
       " 'Peru',\n",
       " 'Philippines',\n",
       " 'Poland',\n",
       " 'Portugal',\n",
       " 'Puerto Rico',\n",
       " 'Qatar',\n",
       " 'Romania',\n",
       " 'Russian Federation',\n",
       " 'Rwanda',\n",
       " 'Samoa',\n",
       " 'Sao Tome and Principe',\n",
       " 'Saudi Arabia',\n",
       " 'Senegal',\n",
       " 'Serbia',\n",
       " 'Seychelles',\n",
       " 'Sierra Leone',\n",
       " 'Singapore',\n",
       " 'Slovak Republic',\n",
       " 'Slovenia',\n",
       " 'Solomon Islands',\n",
       " 'Somalia',\n",
       " 'South Africa',\n",
       " 'South Sudan',\n",
       " 'Spain',\n",
       " 'Sri Lanka',\n",
       " 'Sudan',\n",
       " 'Suriname',\n",
       " 'Sweden',\n",
       " 'Switzerland',\n",
       " 'Syrian Arab Republic',\n",
       " 'Tajikistan',\n",
       " 'Tanzania',\n",
       " 'Thailand',\n",
       " 'Timor-Leste',\n",
       " 'Togo',\n",
       " 'Tonga',\n",
       " 'Trinidad and Tobago',\n",
       " 'Tunisia',\n",
       " 'Turkey',\n",
       " 'Turkmenistan',\n",
       " 'Tuvalu',\n",
       " 'Uganda',\n",
       " 'Ukraine',\n",
       " 'United Arab Emirates',\n",
       " 'United Kingdom',\n",
       " 'United States',\n",
       " 'Uruguay',\n",
       " 'Uzbekistan',\n",
       " 'Vanuatu',\n",
       " 'Venezuela, RB',\n",
       " 'Vietnam',\n",
       " 'Yemen, Rep.',\n",
       " 'Zambia',\n",
       " 'Zimbabwe']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read amended csv file\n",
    "c = pd.read_csv('utils/countries_wb.csv', dtype=str, delimiter=';', header=None)\n",
    "countries = list(c[0])\n",
    "\n",
    "# check\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# 1) weighted k nearest neighbour (w-kNN)\n",
    "\n",
    "The w-kNN algorithm is straightforward: we calculate how similar countries are in each given year $y$ with the standardised Euclidean distance $E_y$ and take the inverse of the absolute $|E_y|$ as the weight to impute missing values in any given country $c_i$ in each given year $y$ for each given sub-indicator $j$.\n",
    "\n",
    "A good start to understand this algorithm is to understand high-dimensional space: https://youtu.be/wvsE8jm1GzE\n",
    "\n",
    "### Euclidean distance\n",
    "The Euclidean distance $e_y$ for year $y$ for any given pair of countries $(c_i, c_k)$ for any given sub-indicator $j$ is calculated by:\n",
    "$$ e_y(c_{i}, c_{k}) = \\lVert c_{i}, c_{k} \\rVert_2 = \\sqrt{ \\sum_{j=1}^J(c_{ij} - c_{kj})^2} $$\n",
    "\n",
    "We calculate the squared distances between any given pair of countries $(c_i, c_k)$, but do not consider the country $k+1$ which has the largest distance $e_y$ to country $i$. We do so for any given sub-indicator $j$ and take the square root of it. $c_{ij}$ is the sub-indicator $j$ of country $i$, and $i \\neq k$. Thus, any unique pair of countries $i$ and $k$, $i \\neq k$, has **one** Euclidean distance $e_y$ for year $y$ only.\n",
    "\n",
    "Afterwards, we normalise this with respect to the country $k+1$ which has the largest distance $e_y$ to country $i$ by the following equation:\n",
    "\n",
    "$$ E_y(c_{i}, c_{k}) = \\frac{e_y(c_{i}, c_{k})}{e_y(c_{i}, c_{k+1})} $$\n",
    "\n",
    "This can be seen as equivalent to the well-known normalisation equation:\n",
    "\n",
    "$$\n",
    "x_n = \\frac{x - x_{min}}{x_{max}-x_{min}}\n",
    "$$\n",
    "\n",
    "since $x_{min}$ is always 0, because the distance \"between\" the same country is 0.\n",
    "\n",
    "### Imputations\n",
    "We want that our imputations $x^{j}_{i,y}$ for missing sub-indicator $j$ in country $i$ in year $y$ are similar to sub-indicators $j$ of countries $k$ which have a **small** Euclidean distance $E_y$ and dissimilar to sub-indicators $j$ of countries $k$ which have a **large** Euclidean distance $E_y$. Consequently, the imputations $x^{j}_{i,y}$ are the *weighted* averages where the *weights* are equal to the inverse standardised Euclidean distance $\\frac{1}{|E_y(c_{i}, c_{k})|}$.\n",
    "\n",
    "First, we compute $E_y$ for all available pairs of sub-indicators $j$ amongst two countries $i$ and $k$. Since countries have different amounts of available data points, we average by multiplying the sum by $1/J$, where $J$ is the total number of sub-indicators taken into account here. Note, this does not necessarily be 375, because we have missing values for many sub-indicators. Second, we sum over $k$ to add together all weighted $x^j_{k,y}$ of each unique pair of countries $i$ and $k$ and compute its average by dividing by $K$.\n",
    "\n",
    "$$ x^{j}_{i,y} = \\frac{1}{K} \\sum_k \\frac{1}{|E_y(c_{i}, c_{k})|} \\cdot x^j_{k,y} $$\n",
    "\n",
    "**Assumptions:** we calculate how similar countries are according to their values for *all* sub-indicators in a given year. We assume that the specific sub-indicators which do not have values in this given year are exactly as similar as the ones which we can calculate a distance for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Let's have a final check before we start our w-kNN algorithm to compute all missing values. We have here negative values which might sound confusing, but bear in mind that we have standardised the data before, i.e. the data distribution has mean 0 and standard deviation 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>TimePeriod</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>...</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EG.CFT.ACCS.ZS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641392</td>\n",
       "      <td>0.732207</td>\n",
       "      <td>0.799586</td>\n",
       "      <td>0.877218</td>\n",
       "      <td>0.925555</td>\n",
       "      <td>0.976822</td>\n",
       "      <td>1.011976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.ZS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.783718</td>\n",
       "      <td>-0.942031</td>\n",
       "      <td>0.694039</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.369409</td>\n",
       "      <td>0.768609</td>\n",
       "      <td>1.190220</td>\n",
       "      <td>1.461546</td>\n",
       "      <td>1.449148</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.RU.ZS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.755535</td>\n",
       "      <td>-1.354031</td>\n",
       "      <td>0.870741</td>\n",
       "      <td>-0.154748</td>\n",
       "      <td>0.206070</td>\n",
       "      <td>0.637647</td>\n",
       "      <td>1.126894</td>\n",
       "      <td>1.450451</td>\n",
       "      <td>1.542347</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.UR.ZS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621267</td>\n",
       "      <td>1.023083</td>\n",
       "      <td>-0.269228</td>\n",
       "      <td>0.565059</td>\n",
       "      <td>0.822012</td>\n",
       "      <td>0.971654</td>\n",
       "      <td>1.017390</td>\n",
       "      <td>1.023083</td>\n",
       "      <td>0.606209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FX.OWN.TOTL.ZS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.744066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.669492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.413558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_MTMP</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903891</td>\n",
       "      <td>0.955016</td>\n",
       "      <td>1.560756</td>\n",
       "      <td>-1.283187</td>\n",
       "      <td>-1.286830</td>\n",
       "      <td>-1.096841</td>\n",
       "      <td>0.596543</td>\n",
       "      <td>0.710603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_PDAN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_PDLN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_PDYN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_MISS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "TimePeriod         1990  1991  1992  1993  1994  1995  1996  1997  1998  1999  \\\n",
       "EG.CFT.ACCS.ZS      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "EG.ELC.ACCS.ZS      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "EG.ELC.ACCS.RU.ZS   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "EG.ELC.ACCS.UR.ZS   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "FX.OWN.TOTL.ZS      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "...                 ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "VC_DSR_MTMP         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "VC_DSR_PDAN         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "VC_DSR_PDLN         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "VC_DSR_PDYN         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "VC_DSR_MISS         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "TimePeriod         ...      2010      2011      2012      2013      2014  \\\n",
       "EG.CFT.ACCS.ZS     ...  0.641392  0.732207  0.799586  0.877218  0.925555   \n",
       "EG.ELC.ACCS.ZS     ... -0.783718 -0.942031  0.694039  0.003795  0.369409   \n",
       "EG.ELC.ACCS.RU.ZS  ... -0.755535 -1.354031  0.870741 -0.154748  0.206070   \n",
       "EG.ELC.ACCS.UR.ZS  ... -0.621267  1.023083 -0.269228  0.565059  0.822012   \n",
       "FX.OWN.TOTL.ZS     ...       NaN -0.744066       NaN       NaN -0.669492   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "VC_DSR_MTMP        ...  0.903891  0.955016  1.560756 -1.283187 -1.286830   \n",
       "VC_DSR_PDAN        ...       NaN       NaN       NaN       NaN       NaN   \n",
       "VC_DSR_PDLN        ...       NaN       NaN       NaN       NaN       NaN   \n",
       "VC_DSR_PDYN        ...       NaN       NaN       NaN       NaN       NaN   \n",
       "VC_DSR_MISS        ...       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "TimePeriod             2015      2016      2017      2018  2019  \n",
       "EG.CFT.ACCS.ZS     0.976822  1.011976       NaN       NaN   NaN  \n",
       "EG.ELC.ACCS.ZS     0.768609  1.190220  1.461546  1.449148   NaN  \n",
       "EG.ELC.ACCS.RU.ZS  0.637647  1.126894  1.450451  1.542347   NaN  \n",
       "EG.ELC.ACCS.UR.ZS  0.971654  1.017390  1.023083  0.606209   NaN  \n",
       "FX.OWN.TOTL.ZS          NaN       NaN  1.413558       NaN   NaN  \n",
       "...                     ...       ...       ...       ...   ...  \n",
       "VC_DSR_MTMP       -1.096841  0.596543  0.710603       NaN   NaN  \n",
       "VC_DSR_PDAN             NaN       NaN       NaN  0.000000   NaN  \n",
       "VC_DSR_PDLN             NaN       NaN       NaN  0.000000   NaN  \n",
       "VC_DSR_PDYN             NaN       NaN       NaN  0.000000   NaN  \n",
       "VC_DSR_MISS             NaN       NaN       NaN       NaN   NaN  \n",
       "\n",
       "[400 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_all_std['Iraq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT\n",
    "dict_e = pickle.load(open('utils/data/distances_unstd.pkl', 'rb'))\n",
    "dict_E = pickle.load(open('utils/data/distances_std.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "print('unstandardised distance e:', dict_e['2000', 'Afghanistan', 'Colombia'])\n",
    "print('standardised distance E:  ', dict_E['2000', 'Afghanistan', 'Colombia'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Calculating the Euclidean distance\n",
    "\n",
    "We can calculate the standardised distance $E_y(c_{i}, c_{k})$ after having prepared everything. We do this for each unique pair of two *countries* in each year. In other words, we do not want to calculate $E_y(c_{i}, c_{k})$ for $i = k$ and $E_y(c_{i}, c_{k}) = E_y(c_{k}, c_{i})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python package <code>itertools</code> can help us generating the unique pairs of countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# create list out of all unique combinations\n",
    "countrycombinations = list(itertools.combinations(countries, 2))\n",
    "countrycombinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# check\n",
    "countrycombinations[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Here, we calculate the standardised distance $E_y(c_{i}, c_{k})$ for each unique pair of two countries in each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "First, we compute the (not standardised) distances $e_y$ and insert them into a new dictionary `dict_e`.\n",
    "\n",
    "While exploring the data, we see that nearly no data are available for the years `1990` to `1999`. Consequently, imputations in those years will be based on very weak foundations and we do not consider these years for now. For our similarity investigations later, it does not matter much how many data points we have totally available per country, it is more important that all countries have the same amount of data points. For now, we also omit data for the year `2019`, because it seems not all countries have reported their data yet. Hence, there aren't too many data points available neither.\n",
    "\n",
    "We set the `period` of years we want to consider in our computations for $e_y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "period = ['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "401\n"
     ]
    }
   ],
   "source": [
    "# call seriescodes again\n",
    "info = pd.read_csv('utils/wb_info.csv', header=None, dtype=str)\n",
    "#seriescodes = list(info['Series Code'])\n",
    "seriescodes = list(dict_all['Germany'].index)\n",
    "print(len(seriescodes))\n",
    "print(len(info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperature\n"
     ]
    }
   ],
   "source": [
    "for seriescode in seriescodes:\n",
    "    if seriescode not in list(info[0]):\n",
    "        print(seriescode)\n",
    "\n",
    "print()\n",
    "\n",
    "for seriescode in list(info[0]):\n",
    "    if seriescode not in seriescodes:\n",
    "        print(seriescode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>EN.CLC.DRSK.XQ</td>\n",
       "      <td>Environment: Land use</td>\n",
       "      <td>Disaster risk reduction progress score (1-5 sc...</td>\n",
       "      <td>13</td>\n",
       "      <td>13.2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>EN.CLC.MDAT.ZS</td>\n",
       "      <td>Environment: Land use</td>\n",
       "      <td>Droughts, floods, extreme temperatures (% of p...</td>\n",
       "      <td>13</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>SG_DSR_SILN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Number of local governments that adopt and imp...</td>\n",
       "      <td>13</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>SG_DSR_SILS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Proportion of local governments that adopt and...</td>\n",
       "      <td>13</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>SG_GOV_LOGV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Number of local governments (number)</td>\n",
       "      <td>13</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>VC_DSR_AFFCT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Number of people affected by disaster (number)</td>\n",
       "      <td>13</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>VC_DSR_DAFF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Number of directly affected persons attributed...</td>\n",
       "      <td>13</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>VC_DSR_IJILN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Number of injured or ill people attributed to ...</td>\n",
       "      <td>13</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>VC_DSR_MISS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Number of missing persons due to disaster (num...</td>\n",
       "      <td>13</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>VC_DSR_MORT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Number of deaths due to disaster (number)</td>\n",
       "      <td>13</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>VC_DSR_MTMN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Number of deaths and missing persons attribute...</td>\n",
       "      <td>13</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>VC_DSR_MTMP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Number of deaths and missing persons attribute...</td>\n",
       "      <td>13</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>VC_DSR_PDAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Number of people whose damaged dwellings were ...</td>\n",
       "      <td>13</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>VC_DSR_PDLN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Number of people whose livelihoods were disrup...</td>\n",
       "      <td>13</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>VC_DSR_PDYN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Number of people whose destroyed dwellings wer...</td>\n",
       "      <td>13</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0                      1  \\\n",
       "310  EN.CLC.DRSK.XQ  Environment: Land use   \n",
       "311  EN.CLC.MDAT.ZS  Environment: Land use   \n",
       "388     SG_DSR_SILN                    NaN   \n",
       "389     SG_DSR_SILS                    NaN   \n",
       "390     SG_GOV_LOGV                    NaN   \n",
       "391    VC_DSR_AFFCT                    NaN   \n",
       "392     VC_DSR_DAFF                    NaN   \n",
       "393    VC_DSR_IJILN                    NaN   \n",
       "394     VC_DSR_MISS                    NaN   \n",
       "395     VC_DSR_MORT                    NaN   \n",
       "396     VC_DSR_MTMN                    NaN   \n",
       "397     VC_DSR_MTMP                    NaN   \n",
       "398     VC_DSR_PDAN                    NaN   \n",
       "399     VC_DSR_PDLN                    NaN   \n",
       "400     VC_DSR_PDYN                    NaN   \n",
       "\n",
       "                                                     2   3     4   5  \n",
       "310  Disaster risk reduction progress score (1-5 sc...  13  13.2  -1  \n",
       "311  Droughts, floods, extreme temperatures (% of p...  13  13.1  -1  \n",
       "388  Number of local governments that adopt and imp...  13  13.1   1  \n",
       "389  Proportion of local governments that adopt and...  13  13.1   1  \n",
       "390               Number of local governments (number)  13  13.1   1  \n",
       "391    Number of people affected by disaster (number)   13  13.1  -1  \n",
       "392  Number of directly affected persons attributed...  13  13.1  -1  \n",
       "393  Number of injured or ill people attributed to ...  13  13.1  -1  \n",
       "394  Number of missing persons due to disaster (num...  13  13.1  -1  \n",
       "395          Number of deaths due to disaster (number)  13  13.1  -1  \n",
       "396  Number of deaths and missing persons attribute...  13  13.1  -1  \n",
       "397  Number of deaths and missing persons attribute...  13  13.1  -1  \n",
       "398  Number of people whose damaged dwellings were ...  13  13.1  -1  \n",
       "399  Number of people whose livelihoods were disrup...  13  13.1  -1  \n",
       "400  Number of people whose destroyed dwellings wer...  13  13.1  -1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if '8.10' became 8.1 (8 is only SDG with a target number 10 in the current version of data)\n",
    "info[info[3]=='13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "dict_all_std['Iraq'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Euclidean distances computed with vectors of different dimensions\n",
    "\n",
    "Simply computing the Euclidean distance between all the countries we have won't give us the results we like, because each of the pairs of countries we calculate the Euclidean distance for has different many measurements to take into account.\n",
    "\n",
    "We consider this by counting how many measurements `j` we have for each pair of countries and setting the weight `w` as the invesre of the number of measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ~ one hour computing time\n",
    "# no need to run every time again, just see CHECKPOINT above and load pickle file\n",
    "\n",
    "dict_e = {}    \n",
    "\n",
    "for year in period:\n",
    "    print(year)\n",
    "    \n",
    "    for countrycombination in tqdm(countrycombinations):\n",
    "        \n",
    "        country0_e = []    # create two empty lists for the two groupings we consider at the moment\n",
    "        country1_e = []    # these lists contain series codes with data available in both groupings\n",
    "        j = 0    # counter\n",
    "        \n",
    "        for seriescode in seriescodes:\n",
    "            # we can only consider sub-indicators with data available in both groupings\n",
    "            if pd.isna(dict_all_std[countrycombination[0]].loc[seriescode, year]) is False and pd.isna(dict_all_std[countrycombination[1]].loc[seriescode, year]) is False:\n",
    "                country0_e.append(dict_all_std[countrycombination[0]].loc[seriescode, year])\n",
    "                country1_e.append(dict_all_std[countrycombination[1]].loc[seriescode, year])\n",
    "                \n",
    "                j += 1\n",
    "        \n",
    "        #print('number of data points available: ', j)    # check\n",
    "        if j > 0:\n",
    "            e = distance.euclidean(country0_e, country1_e, w=1/j)\n",
    "        else:\n",
    "            e = np.nan    # make NaN\n",
    "            \n",
    "        #print('e in {} between {} and {}:'.format(year, countrycombination[0], countrycombination[1]), e)\n",
    "        \n",
    "        dict_e[year, countrycombination[1], countrycombination[0]] = e\n",
    "        dict_e[year, countrycombination[0], countrycombination[1]] = dict_e[year, countrycombination[1], countrycombination[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better save these precious data\n",
    "f = open('utils/data/distances_unstd.pkl', 'wb')\n",
    "pickle.dump(dict_e, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT\n",
    "dict_e = pickle.load(open('utils/data/distances_unstd.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "print(dict_e['2011', 'Switzerland', 'Iraq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise these distances $e_y$ and save them in `dict_E`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_E = {}\n",
    "\n",
    "for year in period:\n",
    "    print(year)\n",
    "    \n",
    "    max_e = 0    # maximum value per year\n",
    "    min_e = 0\n",
    "    dict_e_year = {}    # auxiliary dictionary with all distances per year\n",
    "    \n",
    "    for k in dict_e.keys():\n",
    "        if year in k:\n",
    "            dict_e_year[k] = dict_e[k]            \n",
    "\n",
    "    max_e = np.nanmax(list(dict_e_year.values()))\n",
    "\n",
    "    #print('------------')\n",
    "    #print('max_e in {}'.format(year), max_e)\n",
    "    #print('------------')\n",
    "       \n",
    "    for k in dict_e_year.keys():\n",
    "        #print(k)\n",
    "        if np.isnan(dict_e_year[k]) == False:\n",
    "            #print('unstandardised distance e:', dict_e_year[k])\n",
    "            dict_E[k] = dict_e_year[k] / max_e    # standardise distance\n",
    "            \n",
    "        else:\n",
    "            dict_E[k] = np.nan    # keep as NaN\n",
    "        \n",
    "        #print('standardised distance E:', dict_E[k])\n",
    "        #print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "print('unstandardised distance e:', dict_e['2016', 'Afghanistan', 'Colombia'])\n",
    "print('standardised distance E:  ', dict_E['2016', 'Afghanistan', 'Colombia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check (both should be False)\n",
    "print(0 in dict_e.values())\n",
    "print(0 in dict_E.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check \n",
    "min_value = 0.1\n",
    "\n",
    "for key, value in dict_E.items():\n",
    "    if 0 < value < min_value:\n",
    "        min_value = value\n",
    "        print('smallest:', key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# better save these precious data\n",
    "f = open('utils/data/distances_std.pkl', 'wb')\n",
    "pickle.dump(dict_E, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Imputations for countries\n",
    "\n",
    "Now, we impute the missing values according to the equation we previously derived:\n",
    "\n",
    "$$ x^{j'}_{i,y} = \\frac{1}{K} \\sum_k \\frac{1}{|E_y(c_{i}, c_{k})|} \\cdot x^j_{k,y} $$\n",
    "\n",
    "To recap, our imputations $x^{j'}_{i,y}$ for missing sub-indicator $j'$ in country $i$ in year $y$ should be similar to sub-indicators $j$ of country $k$, according to the inverse standardised Euclidean distance $\\frac{1}{|E_y(c_{i}, c_{k})|}$ between $i$ and $k$. \n",
    "\n",
    "As aforementioned and shown in the equation of $E_y$, $E_y$ is dependent on the number of pairs we have in both countries data for. Our `dict_E` has already entries for $E$ normalised according to this number of available pairs of data. We multiply our weight for each imputation, i.e. the inverse standardised Euclidean distance $\\frac{1}{|E_y(c_{i}, c_{k})|}$ between $i$ and $k$, by the value $x^j_{k,y}$ of the other country $k$ in year $y$ for sub-indicator $j$. We sum over $k$ to add together all weighted $x^j_{k,y}$ of each unique pair of countries $i$ and $k$ and compute its average by dividing by $K$. $K$ is the number of countries which have values available for the sub-indicator $x^{j'}_{k,y}$ to be computed. \n",
    "\n",
    "We also know that some indicators are **binary**, i.e. 1 for 'yes' and 0 for 'no', and ordinal for groupings of countries. These indicators start usually with 'number of countries which...'. The imputations for these must be handled differently: we round the imputed value to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in UN data set exist binary indicators\n",
    "binary = ['1.5.3', '5.1.1', '5.6.2', '5.a.2', '5.c.1', '8.b.1', '10.7.2', '11.b.1', '12.1.1', '12.7.1', '13.1.2', '13.2.1', '13.3.1', '13.3.2', '13.b.1', '14.c.1', '15.6.1', '15.8.1', '16.10.2', '17.5.1', '17.14.1', '17.16.1', '17.18.2', '17.18.3', '17.19.2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_binary = info.loc[info['Indicator'].isin(binary)]\n",
    "binary_seriescodes = list(info_binary['SeriesCode'])\n",
    "\n",
    "binary_seriescodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# ~30 minutes\n",
    "\n",
    "dict_all_i = {}\n",
    "\n",
    "for country in tqdm(countries):\n",
    "    \n",
    "    dict_all_i[country] = pd.DataFrame(index=seriescodes, columns=period)\n",
    "    \n",
    "    not_countries = [c for c in countries if c != country]\n",
    "    \n",
    "    for seriescode in seriescodes:\n",
    "        for year in period:            \n",
    "            if pd.isna(dict_all_std[country].loc[seriescode, year]) is True:\n",
    "                K = 0\n",
    "                all_k = []\n",
    "                \n",
    "                for not_country in not_countries: \n",
    "                    if pd.isna(dict_all_std[not_country].loc[seriescode, year]) is False and pd.isna(dict_E[(year, country, not_country)]) is False: # and dict_E[(year, country, not_country)]!=0:    # not_country can also have NaN -> exclude those\n",
    "                        K += 1\n",
    "                        # print('value:', dict_all_std[not_country].loc[seriescode, year])\n",
    "                        # print('distance:', dict_E[(year, country, not_country)])\n",
    "                        k = (dict_all_std[not_country].loc[seriescode, year]) / (dict_E[(year, country, not_country)])\n",
    "                        # print('k =', k)\n",
    "                        all_k.append(k)\n",
    "                        \n",
    "                sum_k = np.sum(all_k)\n",
    "                    \n",
    "                #print('K =', K)\n",
    "                    \n",
    "                if K > 0:\n",
    "                    # print('sum k =', sum_k)\n",
    "                    \n",
    "                    \"\"\"\n",
    "                    # only UN data set has binary seriescodes\n",
    "                    if seriescode in binary_seriescodes:\n",
    "                        dict_all_i[country].loc[seriescode, year] = np.around(sum_k / K)    # round to have binary\n",
    "                    else:\n",
    "                        dict_all_i[country].loc[seriescode, year] = sum_k / K\n",
    "                    \"\"\"\n",
    "                    dict_all_i[country].loc[seriescode, year] = sum_k / K\n",
    "                            \n",
    "                else:\n",
    "                    dict_all_i[country].loc[seriescode, year] = np.nan    # only impute when data of other countries is available, 0 cannot be imputed because time-series are non-stationary\n",
    "                \n",
    "                #print('Imputation for {} in {} in {}'.format(seriescode, country, year), dict_all_i[country].loc[seriescode, year])        \n",
    "                \n",
    "            else:\n",
    "                dict_all_i[country].loc[seriescode, year] = dict_all_std[country].loc[seriescode, year]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to delete all keys which are not part of the list of countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of keys to delete\n",
    "delete_keys = []\n",
    "\n",
    "for key in dict_all_i.keys():\n",
    "    if key not in countries:\n",
    "        delete_keys.append(key)\n",
    "        \n",
    "# delete\n",
    "#for dk in delete_keys:\n",
    "#    dict_all_i.pop(dk, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check \n",
    "max_values = []\n",
    "\n",
    "for c in dict_all_i.keys():\n",
    "    max_values.append(dict_all_i[c].max().max())\n",
    "    \n",
    "max(max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "print('NaN here', dict_all_std['Afghanistan'].loc['SE.SEC.UNER.LO.ZS', '2016'])\n",
    "print('Imputed value', dict_all_i['Afghanistan'].loc['SE.SEC.UNER.LO.ZS', '2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "dict_all_i['Afghanistan'].loc['SE.SEC.UNER.LO.ZS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to save the imputations to have another checkpoint here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# as csv files\n",
    "if not os.path.exists('csv_imputed'):\n",
    "    os.mkdir('csv_imputed')\n",
    "\n",
    "for c in countries:\n",
    "    dict_all_i[c].to_csv(r'csv_imputed/{}_wb.csv'.format(c))\n",
    "    \n",
    "# as pkl files\n",
    "imp = open('utils/data/dict_all_i_wb.pkl', 'wb')\n",
    "pickle.dump(dict_all_i, imp)\n",
    "imp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT\n",
    "dict_all_i = pickle.load(open('utils/data/dict_all_i_wb.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the total number of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # values before imputations: 844553\n",
      "Total # values after imputations: 1177422\n",
      "How many have been imputed? 332869\n",
      "This accounts for 39.41 % of the total data available now\n"
     ]
    }
   ],
   "source": [
    "# number of values\n",
    "s_imp = 0\n",
    "for country in dict_all_i.keys():\n",
    "    s_imp += np.sum(dict_all_i[country].count())\n",
    "\n",
    "print('Total # values before imputations:', s)\n",
    "print('Total # values after imputations:', s_imp)\n",
    "print('How many have been imputed?', s_imp - s)\n",
    "print('This accounts for', round(100*(s_imp-s)/s, 2), '% of the total data available now')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging and concatenating data to higher levels\n",
    "\n",
    "### *(UN data set only)* Averaging and concatenating series codes data to indicator-level\n",
    "\n",
    "1. We can average all series codes, i.e. sub-indicators, belonging to one indicator to this indicator.\n",
    "2. We can see the series codes as multiple samples of the same indicator and concatenate the series codes into indicators. Consequently, we have more than one measurement per time point for any indicators having more than one series code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = list(info.Indicator)\n",
    "\n",
    "dict_indicators = {}\n",
    "\n",
    "for indicator in indicators:\n",
    "    i = info['SeriesCode'].where(info['Indicator'] == indicator)\n",
    "\n",
    "    dict_indicators[indicator] = [s for s in i if str(s) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "np.isnan(dict_all_i['Germany'].loc['SI_POV_DAY1', '2001'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indicators_values = {}\n",
    "#indicators_values_std = {}\n",
    "indicators_values_i = {}\n",
    "\n",
    "for country in countries:\n",
    "    #print(country)\n",
    "    \n",
    "    #indicators_values[country] = pd.DataFrame(columns=period, index=indicators)\n",
    "    #indicators_values_std[country] = pd.DataFrame(columns=period, index=indicators)\n",
    "    indicators_values_i[country] = pd.DataFrame(columns=period, index=list(dict_indicators.keys()))\n",
    "    \n",
    "    for year in period:\n",
    "        \n",
    "        for indicator in dict_indicators.keys():\n",
    "            #list_subindicators_values = []\n",
    "            #list_subindicators_values_std = []\n",
    "            list_subindicators_values_i = []\n",
    "    \n",
    "            for subindicator in list(dict_indicators[indicator]):\n",
    "                if np.isnan(dict_all_i[country].loc[subindicator, year]):\n",
    "                    pass\n",
    "                else:\n",
    "                    #list_subindicators_values.append(dict_all[country].loc[subindicator, year])\n",
    "                    #list_subindicators_values_std.append(dict_all_std[country].loc[subindicator, year])\n",
    "                    list_subindicators_values_i.append(dict_all_i[country].loc[subindicator, year])\n",
    "            \n",
    "            # 1. averaging\n",
    "            #indicators_values[country].loc[indicator, year] = np.nanmean(list_subindicators_values)\n",
    "            #indicators_values_std[country].loc[indicator, year] = np.nanmean(list_subindicators_values_std)\n",
    "            #indicators_values_i[country].loc[indicator, year] = np.nanmean(list_subindicators_values_i)\n",
    "            \n",
    "            # 2. concatenating\n",
    "            array_subindicators_values_i = np.asarray(list_subindicators_values_i)\n",
    "            indicators_values_i[country].loc[indicator, year] = array_subindicators_values_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check (duplicate indicator labels should be in index)\n",
    "indicators_values_i['Germany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better save these precious data\n",
    "#ind_val = open('utils/data/indicators_values.pkl', 'wb')\n",
    "#ind_val_std = open('utils/data/indicators_values_std.pkl', 'wb')\n",
    "ind_val_i = open('utils/data/indicators_values_i.pkl', 'wb')\n",
    "#pickle.dump(indicators_values, ind_val)\n",
    "#pickle.dump(indicators_values_std, ind_val_std)\n",
    "pickle.dump(indicators_values_i, ind_val_i)\n",
    "#ind_val.close()\n",
    "#ind_val_std.close()\n",
    "ind_val_i.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *(UN data set)* Averaging and concatenating indicator data to target-level\n",
    "We must also generate two lists of indicators which are meant to increase and decrease over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gone though all targets by hand and checked which indicators are meant to increase and which are meant to decrease over time.\n",
    "increase = ['1.3.1', '1.4.1', '1.4.2', '1.5.3', '1.5.4', '1.a.1', '1.a.2', '1.a.3', '1.b.1', '2.3.1', '2.3.2', '2.4.1', '2.5.1', '2.a.1', '2.a.2', '3.1.2', '3.5.1', '3.7.1', '3.8.1', '3.b.1', '3.b.2', '3.b.3', '3.c.1', '3.d.1', '4.1.1', '4.2.1', '4.2.2', '4.3.1', '4.4.1', '4.6.1', '4.7.1', '4.a.1', '4.b.1', '4.c.1', '5.1.1', '5.5.1', '5.5.2', '5.6.1', '5.6.2', '5.a.1', '5.a.2', '5.b.1', '5.c.1', '6.1.1', '6.2.1', '6.3.1', '6.3.2', '6.4.1', '6.5.1', '6.5.2', '6.6.1', '6.a.1', '6.b.1', '7.1.1', '7.1.2', '7.2.1', '7.3.1', '7.a.1', '7.b.1', '8.1.1', '8.2.1', '8.3.1', '8.5.1', '8.8.2', '8.9.1', '8.9.2', '8.10.1', '8.10.2', '8.a.1', '8.b.1', '9.1.1', '9.1.2', '9.2.1', '9.2.2', '9.3.1', '9.3.2', '9.5.1', '9.5.2', '9.a.1', '9.b.1', '9.c.1', '10.1.1', '10.4.1', '10.5.1', '10.6.1', '10.7.2', '10.a.1', '10.b.1', '11.2.1', '11.3.2', '11.4.1', '11.6.1', '11.7.1', '11.a.1', '11.b.1', '11.b.2', '11.c.1', '12.1.1', '12.4.1', '12.5.1', '12.6.1', '12.7.1', '12.8.1', '12.a.1', '12.b.1', '13.1.2', '13.1.3', '13.2.1', '13.3.1', '13.3.2', '13.a.1', '13.b.1', '14.2.1', '14.3.1', '14.4.1', '14.5.1', '14.6.1', '14.7.1', '14.a.1', '14.b.1', '14.c.1', '15.1.1', '15.1.2', '15.2.1', '15.4.1', '15.4.2', '15.6.1', '15.8.1', '15.9.1', '15.a.1', '15.b.1', '16.1.4', '16.6.2', '16.7.1', '16.7.2', '16.8.1', '16.9.1', '16.10.2', '16.a.1', '17.1.1', '17.1.2', '17.2.1', '17.3.1', '17.3.2', '17.4.1', '17.5.1', '17.6.1', '17.6.2', '17.7.1', '17.8.1', '17.9.1', '17.11.1', '17.13.1', '17.14.1', '17.15.1', '17.16.1', '17.17.1', '17.18.1', '17.18.2', '17.18.3', '17.19.1', '17.19.2']\n",
    "decrease = ['1.1.1', '1.2.1', '1.2.2', '1.5.1', '1.5.2', '2.1.1', '2.1.2', '2.2.1', '2.2.2', '2.5.2','2.b.1', '2.c.1', '3.1.1', '3.2.1', '3.2.2', '3.3.1', '3.3.2', '3.3.3', '3.3.4', '3.3.5', '3.4.1', '3.4.2', '3.5.2', '3.6.1', '3.7.2', '3.8.2', '3.9.1', '3.9.2', '3.9.3', '3.a.1', '4.5.1', '5.2.1', '5.2.2', '5.3.1', '5.3.2', '5.4.1', '6.4.2', '8.4.1', '8.4.2', '8.5.2', '8.6.1', '8.7.1', '8.8.1', '9.4.1', '10.2.1', '10.3.1', '10.7.1', '10.c.1', '11.1.1', '11.3.1', '11.5.1', '11.5.2', '11.6.2', '11.7.2', '12.2.1', '12.2.2', '12.3.1', '12.4.2', '12.c.1', '13.1.1', '14.1.1', '15.3.1', '15.5.1', '15.7.1', '15.c.1', '16.1.1', '16.1.2', '16.1.3', '16.2.1', '16.2.2', '16.2.3', '16.3.1', '16.3.2', '16.4.1', '16.4.2', '16.5.1', '16.5.2', '16.6.1', '16.10.1', '16.b.1', '17.10.1', '17.12.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making all time-series \"pointing\" upwards when they are meant to increase\n",
    "\n",
    "indicators_values_i_up = {}\n",
    "\n",
    "for country in countries:\n",
    "    indicators_values_i_up[country] = pd.DataFrame(index=list(dict_indicators.keys()), columns=period)\n",
    "    \n",
    "    for indicator in dict_indicators.keys():\n",
    "        if indicator in decrease:\n",
    "            #indicators_values_up[country].loc[indicator] = indicators_values[country].loc[indicator]*(-1)\n",
    "            #indicators_values_std_up[country].loc[indicator] = indicators_values_std[country].loc[indicator]*(-1)\n",
    "            indicators_values_i_up[country].loc[indicator] = list(np.multiply(list(indicators_values_i[country].loc[indicator]), -1))\n",
    "        else:\n",
    "            #indicators_values_up[country].loc[indicator] = indicators_values[country].loc[indicator]\n",
    "            #indicators_values_std_up[country].loc[indicator] = indicators_values_std[country].loc[indicator]\n",
    "            indicators_values_i_up[country].loc[indicator] = indicators_values_i[country].loc[indicator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check\n",
    "indicators_values_i_up['Germany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better save these precious data\n",
    "#ind_val = open('utils/data/indicators_values_up.pkl', 'wb')\n",
    "#ind_val_std = open('utils/data/indicators_values_std_up.pkl', 'wb')\n",
    "ind_val_i = open('utils/data/indicators_values_i_up.pkl', 'wb')\n",
    "#pickle.dump(indicators_values_up, ind_val)\n",
    "#pickle.dump(indicators_values_std_up, ind_val_std)\n",
    "pickle.dump(indicators_values_i_up, ind_val_i)\n",
    "#ind_val.close()\n",
    "#ind_val_std.close()\n",
    "ind_val_i.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining dictionaries for targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = list(info['Target'].unique())\n",
    "\n",
    "dict_targets = {}\n",
    "\n",
    "for target in targets:\n",
    "    t = info['Indicator'].where(info['Target'] == target)\n",
    "\n",
    "    dict_targets[target] = [i for i in t if str(i) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "list(indicators_values_i_up['Germany'].loc['1.1.1', '2000'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can simply average or concatenate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_values_i = {}\n",
    "#targets_values_up = {}\n",
    "#targets_values_std_up = {}\n",
    "targets_values_i_up = {}    # for Granger-causality\n",
    "\n",
    "for country in countries:\n",
    "    \n",
    "    #targets_values_up[country] = pd.DataFrame(columns=period, index=targets)\n",
    "    #targets_values_std_up[country] = pd.DataFrame(columns=period, index=targets)\n",
    "    targets_values_i[country] = pd.DataFrame(columns=period, index=list(dict_targets.keys()))\n",
    "    targets_values_i_up[country] = pd.DataFrame(columns=period, index=list(dict_targets.keys()))\n",
    "    \n",
    "    for year in period:\n",
    "        \n",
    "        for target in list(dict_targets.keys()):\n",
    "            #list_indicators_values = []\n",
    "            #list_indicators_values_std = []\n",
    "            list_indicators_values_i = []\n",
    "            list_indicators_values_i_up = []\n",
    "    \n",
    "            for indicator in list(dict_targets[target]):\n",
    "                #list_indicators_values.append(indicators_values[country].loc[indicator, year])\n",
    "                #list_indicators_values_std.append(indicators_values_std[country].loc[indicator, year])\n",
    "                list_indicators_values_i.extend(indicators_values_i[country].loc[indicator, year])\n",
    "                list_indicators_values_i_up.extend(indicators_values_i_up[country].loc[indicator, year])\n",
    "    \n",
    "            #print(list_indicators_values_i)\n",
    "            \n",
    "            # 1. averaging\n",
    "            #targets_values_up[country].loc[target, year] = np.mean(list_indicators_values)\n",
    "            #targets_values_std_up[country].loc[target, year] = np.mean(list_indicators_values_std)\n",
    "            #targets_values_i_up[country].loc[target, year] = np.mean(list_indicators_values_i)\n",
    "            \n",
    "            # 2. concatenating\n",
    "            targets_values_i[country].loc[target, year] = list_indicators_values_i\n",
    "            targets_values_i_up[country].loc[target, year] = list_indicators_values_i_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check (each goal should have list in cells with values for sub-indicators)\n",
    "targets_values_i_up['Germany'].loc['1.1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first inner parentheses in each cell contains the values from the first indicator; the second inner parentheses in each cell contains the values from the second indicator; etc. Each indicator represents a couple of sub-indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better save these precious data\n",
    "#tar_val = open('utils/data/targets_values_up.pkl', 'wb')\n",
    "#tar_val_std = open('utils/data/targets_values_std_up.pkl', 'wb')\n",
    "tar_val_i = open('utils/data/targets_values_i.pkl', 'wb')\n",
    "tar_val_i_up = open('utils/data/targets_values_i_up.pkl', 'wb')\n",
    "#pickle.dump(targets_values_up, tar_val)\n",
    "#pickle.dump(targets_values_std_up, tar_val_std)\n",
    "pickle.dump(targets_values_i, tar_val_i)\n",
    "pickle.dump(targets_values_i_up, tar_val_i_up)\n",
    "#tar_val.close()\n",
    "#tar_val_std.close()\n",
    "tar_val_i.close()\n",
    "tar_val_i_up.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *(UN data set)* Averaging and concatenating target data to goal-level\n",
    "\n",
    "Defining dictionaries for goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals = list(info['Goal'].unique())\n",
    "\n",
    "dict_goals = {}\n",
    "\n",
    "for goal in goals:\n",
    "    g = info['Target'].where(info['Goal'] == goal)\n",
    "\n",
    "    dict_goals[goal] = [t for t in g if str(t) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals_values_i = {}\n",
    "#goals_values_up = {}\n",
    "#goals_values_std_up = {}\n",
    "goals_values_i_up = {}    # for Granger-causality\n",
    "\n",
    "for country in countries:\n",
    "    \n",
    "    #goals_values_up[country] = pd.DataFrame(columns=period, index=goals)\n",
    "    #goals_values_std_up[country] = pd.DataFrame(columns=period, index=goals)\n",
    "    goals_values_i[country] = pd.DataFrame(columns=period, index=list(dict_goals.keys()))\n",
    "    goals_values_i_up[country] = pd.DataFrame(columns=period, index=list(dict_goals.keys()))\n",
    "    \n",
    "    for year in period:\n",
    "        \n",
    "        for goal in goals:\n",
    "            #list_targets_values = []\n",
    "            #list_targets_values_std = []\n",
    "            list_targets_values_i = []\n",
    "            list_targets_values_i_up = []\n",
    "    \n",
    "            for target in list(dict_goals[goal]):\n",
    "                #list_targets_values.append(targets_values_up[country].loc[target, year])\n",
    "                #list_targets_values_std.append(targets_values_std_up[country].loc[target, year])\n",
    "                list_targets_values_i.extend(targets_values_i[country].loc[target, year])\n",
    "                list_targets_values_i_up.extend(targets_values_i_up[country].loc[target, year])\n",
    "    \n",
    "            #print(list_targets_values_i)\n",
    "            \n",
    "            # 1. averaging\n",
    "            #goals_values_up[country].loc[goal, year] = np.mean(list_targets_values)\n",
    "            #goals_values_std_up[country].loc[goal, year] = np.mean(list_targets_values_std)\n",
    "            #goals_values_i_up[country].loc[goal, year] = np.mean(list_targets_values_i)\n",
    "            \n",
    "            # 2. concatenating\n",
    "            goals_values_i[country].loc[goal, year] = list_targets_values_i\n",
    "            goals_values_i_up[country].loc[goal, year] = list_targets_values_i_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check (each goal should have list in cells with values for sub-indicators)\n",
    "goals_values_i_up['Germany'].loc['13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better save these precious data\n",
    "#goa_val = open('utils/data/goals_values_up.pkl', 'wb')\n",
    "#goa_val_std = open('utils/data/goals_values_std_up.pkl', 'wb')\n",
    "goa_val_i = open('utils/data/goals_values_i.pkl', 'wb')\n",
    "goa_val_i_up = open('utils/data/goals_values_i_up.pkl', 'wb')\n",
    "#pickle.dump(goals_values_up, goa_val)\n",
    "#pickle.dump(goals_values_std_up, goa_val_std)\n",
    "pickle.dump(goals_values_i, goa_val_i)\n",
    "pickle.dump(goals_values_i_up, goa_val_i_up)\n",
    "#goa_val.close()\n",
    "#goa_val_std.close()\n",
    "goa_val_i.close()\n",
    "goa_val_i_up.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *(WorldBank data set)* Concatenating indicator data to target-level\n",
    "As we have done with the UN data set, we concatenate indicator data to target-level. We jump over the indicators, because sub-indicators are not mapped to specific indicators in the WorldBank data set, only to targets directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EG.CFT.ACCS.ZS</th>\n",
       "      <td>-1.35195</td>\n",
       "      <td>-1.25444</td>\n",
       "      <td>-1.13359</td>\n",
       "      <td>-0.986638</td>\n",
       "      <td>-0.853422</td>\n",
       "      <td>-0.707846</td>\n",
       "      <td>-0.526563</td>\n",
       "      <td>-0.364506</td>\n",
       "      <td>-0.165369</td>\n",
       "      <td>0.0269017</td>\n",
       "      <td>0.2796</td>\n",
       "      <td>0.506205</td>\n",
       "      <td>0.746543</td>\n",
       "      <td>1.03358</td>\n",
       "      <td>1.28353</td>\n",
       "      <td>1.57331</td>\n",
       "      <td>1.89467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.ZS</th>\n",
       "      <td>-0.78235</td>\n",
       "      <td>-0.733598</td>\n",
       "      <td>-0.605854</td>\n",
       "      <td>-0.497503</td>\n",
       "      <td>-0.305941</td>\n",
       "      <td>-1.44749</td>\n",
       "      <td>-1.23525</td>\n",
       "      <td>-1.01799</td>\n",
       "      <td>-0.707053</td>\n",
       "      <td>-0.582226</td>\n",
       "      <td>-0.695603</td>\n",
       "      <td>-0.675679</td>\n",
       "      <td>0.312007</td>\n",
       "      <td>0.305643</td>\n",
       "      <td>1.09061</td>\n",
       "      <td>0.403608</td>\n",
       "      <td>1.40358</td>\n",
       "      <td>1.40358</td>\n",
       "      <td>1.44226</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.RU.ZS</th>\n",
       "      <td>-0.733462</td>\n",
       "      <td>-0.522547</td>\n",
       "      <td>-0.484096</td>\n",
       "      <td>-0.38091</td>\n",
       "      <td>-0.194669</td>\n",
       "      <td>-1.38556</td>\n",
       "      <td>-1.22335</td>\n",
       "      <td>-1.01222</td>\n",
       "      <td>-0.757409</td>\n",
       "      <td>-0.586469</td>\n",
       "      <td>-0.686047</td>\n",
       "      <td>-0.706401</td>\n",
       "      <td>0.279194</td>\n",
       "      <td>0.29284</td>\n",
       "      <td>1.08753</td>\n",
       "      <td>0.396553</td>\n",
       "      <td>1.42153</td>\n",
       "      <td>1.4213</td>\n",
       "      <td>1.45851</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.UR.ZS</th>\n",
       "      <td>-0.270181</td>\n",
       "      <td>-0.859526</td>\n",
       "      <td>-1.0385</td>\n",
       "      <td>-1.47579</td>\n",
       "      <td>-1.36558</td>\n",
       "      <td>-2.00154</td>\n",
       "      <td>-1.20267</td>\n",
       "      <td>-0.984045</td>\n",
       "      <td>-0.00568185</td>\n",
       "      <td>-0.54267</td>\n",
       "      <td>-0.896915</td>\n",
       "      <td>-0.423962</td>\n",
       "      <td>0.6345</td>\n",
       "      <td>0.342497</td>\n",
       "      <td>1.09895</td>\n",
       "      <td>0.320685</td>\n",
       "      <td>1.19937</td>\n",
       "      <td>1.19937</td>\n",
       "      <td>1.26213</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FX.OWN.TOTL.ZS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.88423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.513711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.39794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_AFFCT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0202154</td>\n",
       "      <td>-0.299089</td>\n",
       "      <td>0.209577</td>\n",
       "      <td>0.445943</td>\n",
       "      <td>0.12587</td>\n",
       "      <td>0.300882</td>\n",
       "      <td>-0.204204</td>\n",
       "      <td>-0.256435</td>\n",
       "      <td>-0.358036</td>\n",
       "      <td>-0.406382</td>\n",
       "      <td>-0.238008</td>\n",
       "      <td>0.199867</td>\n",
       "      <td>-1.39779</td>\n",
       "      <td>0.512805</td>\n",
       "      <td>0.884988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_IJILN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.164788</td>\n",
       "      <td>0.0675116</td>\n",
       "      <td>0.12059</td>\n",
       "      <td>0.0183087</td>\n",
       "      <td>0.0611822</td>\n",
       "      <td>-0.117988</td>\n",
       "      <td>0.0803871</td>\n",
       "      <td>-0.479194</td>\n",
       "      <td>0.52016</td>\n",
       "      <td>-0.401456</td>\n",
       "      <td>0.00872788</td>\n",
       "      <td>0.204403</td>\n",
       "      <td>-0.832446</td>\n",
       "      <td>-0.573866</td>\n",
       "      <td>1.40631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_MISS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.269949</td>\n",
       "      <td>-0.185427</td>\n",
       "      <td>-0.362423</td>\n",
       "      <td>0.433348</td>\n",
       "      <td>0.0244812</td>\n",
       "      <td>0.468294</td>\n",
       "      <td>-0.315774</td>\n",
       "      <td>-0.539588</td>\n",
       "      <td>0.399386</td>\n",
       "      <td>0.177468</td>\n",
       "      <td>-0.118247</td>\n",
       "      <td>-0.780321</td>\n",
       "      <td>0</td>\n",
       "      <td>0.316147</td>\n",
       "      <td>0.0751732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_PDAN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0262787</td>\n",
       "      <td>-0.0597579</td>\n",
       "      <td>0.128245</td>\n",
       "      <td>0.502569</td>\n",
       "      <td>0.147331</td>\n",
       "      <td>0.18156</td>\n",
       "      <td>-0.587881</td>\n",
       "      <td>-0.205999</td>\n",
       "      <td>-0.18291</td>\n",
       "      <td>-0.0112419</td>\n",
       "      <td>-0.39095</td>\n",
       "      <td>-0.150397</td>\n",
       "      <td>-0.737766</td>\n",
       "      <td>-0.675998</td>\n",
       "      <td>1.41376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_MTMN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>-0.111366</td>\n",
       "      <td>0.249202</td>\n",
       "      <td>0.423021</td>\n",
       "      <td>0.276401</td>\n",
       "      <td>0.478237</td>\n",
       "      <td>0.23986</td>\n",
       "      <td>-0.263547</td>\n",
       "      <td>-0.200851</td>\n",
       "      <td>-0.449352</td>\n",
       "      <td>-0.0946502</td>\n",
       "      <td>-0.310817</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.366866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       2000      2001      2002      2003      2004  \\\n",
       "EG.CFT.ACCS.ZS     -1.35195  -1.25444  -1.13359 -0.986638 -0.853422   \n",
       "EG.ELC.ACCS.ZS     -0.78235 -0.733598 -0.605854 -0.497503 -0.305941   \n",
       "EG.ELC.ACCS.RU.ZS -0.733462 -0.522547 -0.484096  -0.38091 -0.194669   \n",
       "EG.ELC.ACCS.UR.ZS -0.270181 -0.859526   -1.0385  -1.47579  -1.36558   \n",
       "FX.OWN.TOTL.ZS          NaN       NaN       NaN       NaN       NaN   \n",
       "...                     ...       ...       ...       ...       ...   \n",
       "VC_DSR_AFFCT            NaN       NaN       NaN       NaN       NaN   \n",
       "VC_DSR_IJILN            NaN       NaN       NaN       NaN       NaN   \n",
       "VC_DSR_MISS             NaN       NaN       NaN       NaN       NaN   \n",
       "VC_DSR_PDAN             NaN       NaN       NaN       NaN       NaN   \n",
       "VC_DSR_MTMN             NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "                        2005       2006      2007        2008       2009  \\\n",
       "EG.CFT.ACCS.ZS     -0.707846  -0.526563 -0.364506   -0.165369  0.0269017   \n",
       "EG.ELC.ACCS.ZS      -1.44749   -1.23525  -1.01799   -0.707053  -0.582226   \n",
       "EG.ELC.ACCS.RU.ZS   -1.38556   -1.22335  -1.01222   -0.757409  -0.586469   \n",
       "EG.ELC.ACCS.UR.ZS   -2.00154   -1.20267 -0.984045 -0.00568185   -0.54267   \n",
       "FX.OWN.TOTL.ZS           NaN        NaN       NaN         NaN        NaN   \n",
       "...                      ...        ...       ...         ...        ...   \n",
       "VC_DSR_AFFCT      -0.0202154  -0.299089  0.209577    0.445943    0.12587   \n",
       "VC_DSR_IJILN        0.164788  0.0675116   0.12059   0.0183087  0.0611822   \n",
       "VC_DSR_MISS         0.269949  -0.185427 -0.362423    0.433348  0.0244812   \n",
       "VC_DSR_PDAN       -0.0262787 -0.0597579  0.128245    0.502569   0.147331   \n",
       "VC_DSR_MTMN           0.2075  -0.111366  0.249202    0.423021   0.276401   \n",
       "\n",
       "                       2010       2011      2012      2013       2014  \\\n",
       "EG.CFT.ACCS.ZS       0.2796   0.506205  0.746543   1.03358    1.28353   \n",
       "EG.ELC.ACCS.ZS    -0.695603  -0.675679  0.312007  0.305643    1.09061   \n",
       "EG.ELC.ACCS.RU.ZS -0.686047  -0.706401  0.279194   0.29284    1.08753   \n",
       "EG.ELC.ACCS.UR.ZS -0.896915  -0.423962    0.6345  0.342497    1.09895   \n",
       "FX.OWN.TOTL.ZS          NaN   -0.88423       NaN       NaN  -0.513711   \n",
       "...                     ...        ...       ...       ...        ...   \n",
       "VC_DSR_AFFCT       0.300882  -0.204204 -0.256435 -0.358036  -0.406382   \n",
       "VC_DSR_IJILN      -0.117988  0.0803871 -0.479194   0.52016  -0.401456   \n",
       "VC_DSR_MISS        0.468294  -0.315774 -0.539588  0.399386   0.177468   \n",
       "VC_DSR_PDAN         0.18156  -0.587881 -0.205999  -0.18291 -0.0112419   \n",
       "VC_DSR_MTMN        0.478237    0.23986 -0.263547 -0.200851  -0.449352   \n",
       "\n",
       "                         2015      2016      2017      2018       2019  \n",
       "EG.CFT.ACCS.ZS        1.57331   1.89467       NaN       NaN        NaN  \n",
       "EG.ELC.ACCS.ZS       0.403608   1.40358   1.40358   1.44226        NaN  \n",
       "EG.ELC.ACCS.RU.ZS    0.396553   1.42153    1.4213   1.45851        NaN  \n",
       "EG.ELC.ACCS.UR.ZS    0.320685   1.19937   1.19937   1.26213        NaN  \n",
       "FX.OWN.TOTL.ZS            NaN       NaN   1.39794       NaN        NaN  \n",
       "...                       ...       ...       ...       ...        ...  \n",
       "VC_DSR_AFFCT        -0.238008  0.199867  -1.39779  0.512805   0.884988  \n",
       "VC_DSR_IJILN       0.00872788  0.204403 -0.832446 -0.573866    1.40631  \n",
       "VC_DSR_MISS         -0.118247 -0.780321         0  0.316147  0.0751732  \n",
       "VC_DSR_PDAN          -0.39095 -0.150397 -0.737766 -0.675998    1.41376  \n",
       "VC_DSR_MTMN        -0.0946502 -0.310817        -1 -0.366866          1  \n",
       "\n",
       "[400 rows x 20 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "dict_all_i['Afghanistan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We append these temperature series to the data frame of indicators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pickle.load(open('utils/data/temp.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint:* When the data are downloaded, the names of countries do not match exactly. For example 'Republic of Serbia' is the name in the temperature data set, whereas 'Serbia' is the name in the SDG data set. These are aligned manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# countries in dict_all_i: 183\n",
      "# countries in temp: 182\n"
     ]
    }
   ],
   "source": [
    "print('# countries in dict_all_i:', len(dict_all_i.keys()))\n",
    "print('# countries in temp:', len(temp.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micronesia, Fed. Sts.\n"
     ]
    }
   ],
   "source": [
    "# which country is in dict_all_i but not in temp?\n",
    "for key in dict_all_i.keys():\n",
    "    if key not in temp.keys():\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EG.CFT.ACCS.ZS</th>\n",
       "      <td>-1.49026</td>\n",
       "      <td>-1.08759</td>\n",
       "      <td>-1.08759</td>\n",
       "      <td>-1.08759</td>\n",
       "      <td>-0.886259</td>\n",
       "      <td>-0.517149</td>\n",
       "      <td>-0.785592</td>\n",
       "      <td>-0.450038</td>\n",
       "      <td>0.0868494</td>\n",
       "      <td>0.187516</td>\n",
       "      <td>0.455959</td>\n",
       "      <td>0.288182</td>\n",
       "      <td>0.89218</td>\n",
       "      <td>0.925736</td>\n",
       "      <td>1.09351</td>\n",
       "      <td>1.42907</td>\n",
       "      <td>2.03307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.ZS</th>\n",
       "      <td>-1.61049</td>\n",
       "      <td>-1.38603</td>\n",
       "      <td>-1.21995</td>\n",
       "      <td>-1.05559</td>\n",
       "      <td>-0.893369</td>\n",
       "      <td>-0.733444</td>\n",
       "      <td>-0.574999</td>\n",
       "      <td>-0.41697</td>\n",
       "      <td>-0.258292</td>\n",
       "      <td>-0.097902</td>\n",
       "      <td>0.0918496</td>\n",
       "      <td>0.332583</td>\n",
       "      <td>0.535046</td>\n",
       "      <td>0.715418</td>\n",
       "      <td>0.900091</td>\n",
       "      <td>1.11228</td>\n",
       "      <td>1.32923</td>\n",
       "      <td>1.52484</td>\n",
       "      <td>1.7057</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.RU.ZS</th>\n",
       "      <td>-1.58597</td>\n",
       "      <td>-1.38079</td>\n",
       "      <td>-1.21428</td>\n",
       "      <td>-1.05003</td>\n",
       "      <td>-0.888708</td>\n",
       "      <td>-0.73066</td>\n",
       "      <td>-0.574636</td>\n",
       "      <td>-0.419495</td>\n",
       "      <td>-0.263901</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>0.0571869</td>\n",
       "      <td>0.30503</td>\n",
       "      <td>0.514335</td>\n",
       "      <td>0.704416</td>\n",
       "      <td>0.899446</td>\n",
       "      <td>1.12039</td>\n",
       "      <td>1.34542</td>\n",
       "      <td>1.54428</td>\n",
       "      <td>1.72451</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.UR.ZS</th>\n",
       "      <td>-1.75465</td>\n",
       "      <td>-1.41614</td>\n",
       "      <td>-1.25211</td>\n",
       "      <td>-1.08659</td>\n",
       "      <td>-0.918555</td>\n",
       "      <td>-0.747255</td>\n",
       "      <td>-0.573014</td>\n",
       "      <td>-0.396431</td>\n",
       "      <td>-0.218106</td>\n",
       "      <td>-0.0386346</td>\n",
       "      <td>0.30598</td>\n",
       "      <td>0.504117</td>\n",
       "      <td>0.664011</td>\n",
       "      <td>0.783524</td>\n",
       "      <td>0.902507</td>\n",
       "      <td>1.0579</td>\n",
       "      <td>1.22164</td>\n",
       "      <td>1.392</td>\n",
       "      <td>1.5698</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FX.OWN.TOTL.ZS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.97287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0898346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.68474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_AFFCT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0173213</td>\n",
       "      <td>-0.434783</td>\n",
       "      <td>0.279564</td>\n",
       "      <td>0.493604</td>\n",
       "      <td>0.167349</td>\n",
       "      <td>0.253423</td>\n",
       "      <td>-0.243869</td>\n",
       "      <td>-0.224063</td>\n",
       "      <td>-0.379699</td>\n",
       "      <td>-0.29957</td>\n",
       "      <td>-0.255047</td>\n",
       "      <td>0.188993</td>\n",
       "      <td>0.209677</td>\n",
       "      <td>0.449735</td>\n",
       "      <td>0.0964837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_IJILN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.177932</td>\n",
       "      <td>0.0578615</td>\n",
       "      <td>0.171472</td>\n",
       "      <td>0.0799749</td>\n",
       "      <td>0.140286</td>\n",
       "      <td>-0.085533</td>\n",
       "      <td>0.0881984</td>\n",
       "      <td>-0.448871</td>\n",
       "      <td>0.423552</td>\n",
       "      <td>-0.338018</td>\n",
       "      <td>-0.0418788</td>\n",
       "      <td>0.187574</td>\n",
       "      <td>0.17718</td>\n",
       "      <td>-0.558833</td>\n",
       "      <td>0.307557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_MISS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.304732</td>\n",
       "      <td>-0.179613</td>\n",
       "      <td>-0.373463</td>\n",
       "      <td>0.482428</td>\n",
       "      <td>0.0516246</td>\n",
       "      <td>0.499343</td>\n",
       "      <td>-0.28874</td>\n",
       "      <td>-0.50226</td>\n",
       "      <td>0.297367</td>\n",
       "      <td>0.085688</td>\n",
       "      <td>-0.131804</td>\n",
       "      <td>-0.617854</td>\n",
       "      <td>0.338248</td>\n",
       "      <td>0.262679</td>\n",
       "      <td>0.176379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_PDAN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0245924</td>\n",
       "      <td>-0.153188</td>\n",
       "      <td>0.162795</td>\n",
       "      <td>0.61021</td>\n",
       "      <td>0.247391</td>\n",
       "      <td>0.169794</td>\n",
       "      <td>-0.63921</td>\n",
       "      <td>-0.144229</td>\n",
       "      <td>-0.207599</td>\n",
       "      <td>0.0090181</td>\n",
       "      <td>-0.364593</td>\n",
       "      <td>-0.0973701</td>\n",
       "      <td>0.442774</td>\n",
       "      <td>0.288083</td>\n",
       "      <td>-0.192652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_MTMN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220145</td>\n",
       "      <td>-0.140699</td>\n",
       "      <td>0.282805</td>\n",
       "      <td>0.490427</td>\n",
       "      <td>0.347823</td>\n",
       "      <td>0.477998</td>\n",
       "      <td>0.291104</td>\n",
       "      <td>-0.245749</td>\n",
       "      <td>-0.215054</td>\n",
       "      <td>-0.362608</td>\n",
       "      <td>-0.110804</td>\n",
       "      <td>-0.249221</td>\n",
       "      <td>0.0702376</td>\n",
       "      <td>-0.358344</td>\n",
       "      <td>-0.335294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      2000     2001     2002     2003      2004       2005  \\\n",
       "EG.CFT.ACCS.ZS    -1.49026 -1.08759 -1.08759 -1.08759 -0.886259  -0.517149   \n",
       "EG.ELC.ACCS.ZS    -1.61049 -1.38603 -1.21995 -1.05559 -0.893369  -0.733444   \n",
       "EG.ELC.ACCS.RU.ZS -1.58597 -1.38079 -1.21428 -1.05003 -0.888708   -0.73066   \n",
       "EG.ELC.ACCS.UR.ZS -1.75465 -1.41614 -1.25211 -1.08659 -0.918555  -0.747255   \n",
       "FX.OWN.TOTL.ZS         NaN      NaN      NaN      NaN       NaN        NaN   \n",
       "...                    ...      ...      ...      ...       ...        ...   \n",
       "VC_DSR_AFFCT           NaN      NaN      NaN      NaN       NaN -0.0173213   \n",
       "VC_DSR_IJILN           NaN      NaN      NaN      NaN       NaN   0.177932   \n",
       "VC_DSR_MISS            NaN      NaN      NaN      NaN       NaN   0.304732   \n",
       "VC_DSR_PDAN            NaN      NaN      NaN      NaN       NaN -0.0245924   \n",
       "VC_DSR_MTMN            NaN      NaN      NaN      NaN       NaN   0.220145   \n",
       "\n",
       "                        2006      2007       2008       2009       2010  \\\n",
       "EG.CFT.ACCS.ZS     -0.785592 -0.450038  0.0868494   0.187516   0.455959   \n",
       "EG.ELC.ACCS.ZS     -0.574999  -0.41697  -0.258292  -0.097902  0.0918496   \n",
       "EG.ELC.ACCS.RU.ZS  -0.574636 -0.419495  -0.263901   -0.10655  0.0571869   \n",
       "EG.ELC.ACCS.UR.ZS  -0.573014 -0.396431  -0.218106 -0.0386346    0.30598   \n",
       "FX.OWN.TOTL.ZS           NaN       NaN        NaN        NaN        NaN   \n",
       "...                      ...       ...        ...        ...        ...   \n",
       "VC_DSR_AFFCT       -0.434783  0.279564   0.493604   0.167349   0.253423   \n",
       "VC_DSR_IJILN       0.0578615  0.171472  0.0799749   0.140286  -0.085533   \n",
       "VC_DSR_MISS        -0.179613 -0.373463   0.482428  0.0516246   0.499343   \n",
       "VC_DSR_PDAN        -0.153188  0.162795    0.61021   0.247391   0.169794   \n",
       "VC_DSR_MTMN        -0.140699  0.282805   0.490427   0.347823   0.477998   \n",
       "\n",
       "                        2011      2012      2013       2014       2015  \\\n",
       "EG.CFT.ACCS.ZS      0.288182   0.89218  0.925736    1.09351    1.42907   \n",
       "EG.ELC.ACCS.ZS      0.332583  0.535046  0.715418   0.900091    1.11228   \n",
       "EG.ELC.ACCS.RU.ZS    0.30503  0.514335  0.704416   0.899446    1.12039   \n",
       "EG.ELC.ACCS.UR.ZS   0.504117  0.664011  0.783524   0.902507     1.0579   \n",
       "FX.OWN.TOTL.ZS      -1.97287       NaN       NaN  0.0898346        NaN   \n",
       "...                      ...       ...       ...        ...        ...   \n",
       "VC_DSR_AFFCT       -0.243869 -0.224063 -0.379699   -0.29957  -0.255047   \n",
       "VC_DSR_IJILN       0.0881984 -0.448871  0.423552  -0.338018 -0.0418788   \n",
       "VC_DSR_MISS         -0.28874  -0.50226  0.297367   0.085688  -0.131804   \n",
       "VC_DSR_PDAN         -0.63921 -0.144229 -0.207599  0.0090181  -0.364593   \n",
       "VC_DSR_MTMN         0.291104 -0.245749 -0.215054  -0.362608  -0.110804   \n",
       "\n",
       "                        2016       2017      2018       2019  \n",
       "EG.CFT.ACCS.ZS       2.03307        NaN       NaN        NaN  \n",
       "EG.ELC.ACCS.ZS       1.32923    1.52484    1.7057        NaN  \n",
       "EG.ELC.ACCS.RU.ZS    1.34542    1.54428   1.72451        NaN  \n",
       "EG.ELC.ACCS.UR.ZS    1.22164      1.392    1.5698        NaN  \n",
       "FX.OWN.TOTL.ZS           NaN    1.68474       NaN        NaN  \n",
       "...                      ...        ...       ...        ...  \n",
       "VC_DSR_AFFCT        0.188993   0.209677  0.449735  0.0964837  \n",
       "VC_DSR_IJILN        0.187574    0.17718 -0.558833   0.307557  \n",
       "VC_DSR_MISS        -0.617854   0.338248  0.262679   0.176379  \n",
       "VC_DSR_PDAN       -0.0973701   0.442774  0.288083  -0.192652  \n",
       "VC_DSR_MTMN        -0.249221  0.0702376 -0.358344  -0.335294  \n",
       "\n",
       "[400 rows x 20 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removes key in-place\n",
    "countries.remove('Micronesia, Fed. Sts.')\n",
    "dict_all_i.pop('Micronesia, Fed. Sts.', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "temp['Serbia'] = temp.pop('Republic of Serbia')\n",
    "temp['Montenegro'] = temp.pop('Republic of Montenegro')\n",
    "temp['Timor-Leste'] = temp.pop('Timor Leste')\n",
    "temp['Slovak Republic'] = temp.pop('Slovakia')\n",
    "temp['Micronesia, Fed. Sts.'] = temp.pop('Federated States of Micronesia')\n",
    "temp['Yemen, Rep.'] = temp.pop('Yemen')\n",
    "temp['Syrian Arab Republic'] = temp.pop('Syria')\n",
    "temp.pop('Swaziland')\n",
    "temp['Egypt, Arab Rep.'] = temp.pop('Egypt')\n",
    "temp['Myanmar'] = temp.pop('Myanmar (Burma)')\n",
    "temp['Congo, Dem. Rep.'] = temp.pop('Congo (Democratic Republic of the)')\n",
    "temp['Bahamas, The'] = temp.pop('Bahamas')\n",
    "temp.pop('Northern Mariana Islands')\n",
    "temp.pop('Marshall Islands')\n",
    "temp.pop('Monaco')\n",
    "temp.pop('St. Vincent and the Grenadines')\n",
    "temp.pop('St. Lucia')\n",
    "temp.pop('Andorra')\n",
    "temp.pop('Faroe Islands')\n",
    "temp.pop('Cape Verde')\n",
    "temp.pop('Macedonia')\n",
    "temp['Congo, Rep.'] = temp.pop('Congo (Republic of the)')\n",
    "temp['Iran, Islamic Rep.'] = temp.pop('Iran')\n",
    "temp['Brunei Darussalam'] = temp.pop('Brunei')\n",
    "temp.pop('St. Kitts and Nevis')\n",
    "temp['Kyrgyz Republic'] = temp.pop('Kyrgyzstan')\n",
    "temp['Venezuela, RB'] = temp.pop('Venezuela')\n",
    "temp.pop('New Caledonia')\n",
    "temp['Lao PDR'] = temp.pop('Laos')\n",
    "temp['Russian Federation'] = temp.pop('Russia')\n",
    "temp['Korea, Dem. People\\'s Rep.'] = temp.pop('Korea')\n",
    "temp['Gambia, The'] = temp.pop('Gambia')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in temp.keys():\n",
    "    #print(country)\n",
    "    temp[country] = temp[country].set_index('YEAR').T\n",
    "    temp[country].columns = temp[country].columns.astype(str)\n",
    "    temp[country].rename(index={'AVG': 'Temperature'}, inplace=True)\n",
    "    temp[country] = temp[country].loc['Temperature', period]\n",
    "    temp[country] = pd.Series(scale(temp[country]), index=period, name='Temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000   -0.269217\n",
       "2001    0.759637\n",
       "2002   -0.817939\n",
       "2003   -1.418104\n",
       "2004   -0.097741\n",
       "2005   -0.286364\n",
       "2006   -0.234922\n",
       "2007   -0.817939\n",
       "2008   -0.903677\n",
       "2009   -0.577873\n",
       "2010    2.422951\n",
       "2011   -1.709612\n",
       "2012    0.313800\n",
       "2013   -0.029151\n",
       "2014    0.399538\n",
       "2015    0.725342\n",
       "2016   -0.457840\n",
       "2017   -0.012003\n",
       "2018    1.942819\n",
       "2019    1.068293\n",
       "Name: Temperature, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "temp['Azerbaijan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_all_t = {}\n",
    "\n",
    "for country in temp.keys():\n",
    "    temp[country].index = temp[country].index.astype(int).astype(str)\n",
    "    dict_all_t[country] = dict_all_i[country].append(temp[country])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_to_drop = list(set(list(dict_all_t.keys())).difference(list(temp.keys())))\n",
    "\n",
    "for c in countries_to_drop:\n",
    "    dict_all_t.pop(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EG.CFT.ACCS.ZS</th>\n",
       "      <td>-2.10299</td>\n",
       "      <td>-1.67011</td>\n",
       "      <td>-1.29505</td>\n",
       "      <td>-0.960019</td>\n",
       "      <td>-0.647222</td>\n",
       "      <td>-0.383345</td>\n",
       "      <td>-0.187661</td>\n",
       "      <td>0.0436016</td>\n",
       "      <td>0.271899</td>\n",
       "      <td>0.445346</td>\n",
       "      <td>0.593592</td>\n",
       "      <td>0.722565</td>\n",
       "      <td>0.827819</td>\n",
       "      <td>0.939003</td>\n",
       "      <td>1.04722</td>\n",
       "      <td>1.14506</td>\n",
       "      <td>1.21029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.ZS</th>\n",
       "      <td>-0.865376</td>\n",
       "      <td>-1.24453</td>\n",
       "      <td>0.664812</td>\n",
       "      <td>-0.698185</td>\n",
       "      <td>-0.470713</td>\n",
       "      <td>-0.278292</td>\n",
       "      <td>-0.0359662</td>\n",
       "      <td>0.0550422</td>\n",
       "      <td>0.22844</td>\n",
       "      <td>0.427962</td>\n",
       "      <td>0.578327</td>\n",
       "      <td>0.524656</td>\n",
       "      <td>0.664812</td>\n",
       "      <td>0.664812</td>\n",
       "      <td>0.664812</td>\n",
       "      <td>0.664812</td>\n",
       "      <td>0.664812</td>\n",
       "      <td>0.664812</td>\n",
       "      <td>0.664812</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.RU.ZS</th>\n",
       "      <td>-0.896076</td>\n",
       "      <td>-1.12006</td>\n",
       "      <td>0.61175</td>\n",
       "      <td>-0.519241</td>\n",
       "      <td>-0.287979</td>\n",
       "      <td>-0.115794</td>\n",
       "      <td>-0.0375374</td>\n",
       "      <td>0.120318</td>\n",
       "      <td>0.228841</td>\n",
       "      <td>0.390013</td>\n",
       "      <td>0.52483</td>\n",
       "      <td>0.533782</td>\n",
       "      <td>0.61175</td>\n",
       "      <td>0.61175</td>\n",
       "      <td>0.61175</td>\n",
       "      <td>0.61175</td>\n",
       "      <td>0.61175</td>\n",
       "      <td>0.61175</td>\n",
       "      <td>0.61175</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.UR.ZS</th>\n",
       "      <td>-0.375775</td>\n",
       "      <td>-1.54976</td>\n",
       "      <td>-1.51653</td>\n",
       "      <td>-1.43598</td>\n",
       "      <td>-1.27546</td>\n",
       "      <td>-1.01097</td>\n",
       "      <td>0.0515443</td>\n",
       "      <td>-0.220238</td>\n",
       "      <td>0.26787</td>\n",
       "      <td>0.64741</td>\n",
       "      <td>0.868316</td>\n",
       "      <td>0.501012</td>\n",
       "      <td>0.950479</td>\n",
       "      <td>0.950479</td>\n",
       "      <td>0.950479</td>\n",
       "      <td>0.950479</td>\n",
       "      <td>0.950479</td>\n",
       "      <td>0.950479</td>\n",
       "      <td>0.950479</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FX.OWN.TOTL.ZS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.4133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.66259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_IJILN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.218066</td>\n",
       "      <td>0.0459777</td>\n",
       "      <td>0.0934706</td>\n",
       "      <td>0.0715321</td>\n",
       "      <td>0.0972415</td>\n",
       "      <td>-0.0863218</td>\n",
       "      <td>0.0725582</td>\n",
       "      <td>-0.486512</td>\n",
       "      <td>0.506427</td>\n",
       "      <td>-0.379104</td>\n",
       "      <td>-0.0756324</td>\n",
       "      <td>0.229081</td>\n",
       "      <td>0.126788</td>\n",
       "      <td>-0.541503</td>\n",
       "      <td>0.587335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_MISS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.26197</td>\n",
       "      <td>-0.173728</td>\n",
       "      <td>-0.368545</td>\n",
       "      <td>0.443892</td>\n",
       "      <td>0.0305282</td>\n",
       "      <td>0.535167</td>\n",
       "      <td>-0.396507</td>\n",
       "      <td>-0.539175</td>\n",
       "      <td>0.301976</td>\n",
       "      <td>0.162293</td>\n",
       "      <td>-0.166876</td>\n",
       "      <td>-0.732992</td>\n",
       "      <td>0.382556</td>\n",
       "      <td>0.358528</td>\n",
       "      <td>0.155445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_PDAN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0123201</td>\n",
       "      <td>-0.137992</td>\n",
       "      <td>0.125617</td>\n",
       "      <td>0.532712</td>\n",
       "      <td>0.24665</td>\n",
       "      <td>0.195105</td>\n",
       "      <td>-0.662353</td>\n",
       "      <td>-0.202968</td>\n",
       "      <td>-0.153398</td>\n",
       "      <td>0.0201452</td>\n",
       "      <td>-0.393525</td>\n",
       "      <td>-0.0856296</td>\n",
       "      <td>0.373876</td>\n",
       "      <td>0.285248</td>\n",
       "      <td>-0.296163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_MTMN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.223389</td>\n",
       "      <td>-0.164796</td>\n",
       "      <td>0.226821</td>\n",
       "      <td>0.454255</td>\n",
       "      <td>0.363411</td>\n",
       "      <td>0.476196</td>\n",
       "      <td>0.275943</td>\n",
       "      <td>-0.268863</td>\n",
       "      <td>-0.203482</td>\n",
       "      <td>-0.434208</td>\n",
       "      <td>-0.160559</td>\n",
       "      <td>-0.270496</td>\n",
       "      <td>0.0929166</td>\n",
       "      <td>-0.401371</td>\n",
       "      <td>-0.599375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature</th>\n",
       "      <td>-0.269217</td>\n",
       "      <td>0.759637</td>\n",
       "      <td>-0.817939</td>\n",
       "      <td>-1.4181</td>\n",
       "      <td>-0.0977411</td>\n",
       "      <td>-0.286364</td>\n",
       "      <td>-0.234922</td>\n",
       "      <td>-0.817939</td>\n",
       "      <td>-0.903677</td>\n",
       "      <td>-0.577873</td>\n",
       "      <td>2.42295</td>\n",
       "      <td>-1.70961</td>\n",
       "      <td>0.3138</td>\n",
       "      <td>-0.0291509</td>\n",
       "      <td>0.399538</td>\n",
       "      <td>0.725342</td>\n",
       "      <td>-0.45784</td>\n",
       "      <td>-0.0120033</td>\n",
       "      <td>1.94282</td>\n",
       "      <td>1.06829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       2000      2001      2002      2003       2004  \\\n",
       "EG.CFT.ACCS.ZS     -2.10299  -1.67011  -1.29505 -0.960019  -0.647222   \n",
       "EG.ELC.ACCS.ZS    -0.865376  -1.24453  0.664812 -0.698185  -0.470713   \n",
       "EG.ELC.ACCS.RU.ZS -0.896076  -1.12006   0.61175 -0.519241  -0.287979   \n",
       "EG.ELC.ACCS.UR.ZS -0.375775  -1.54976  -1.51653  -1.43598   -1.27546   \n",
       "FX.OWN.TOTL.ZS          NaN       NaN       NaN       NaN        NaN   \n",
       "...                     ...       ...       ...       ...        ...   \n",
       "VC_DSR_IJILN            NaN       NaN       NaN       NaN        NaN   \n",
       "VC_DSR_MISS             NaN       NaN       NaN       NaN        NaN   \n",
       "VC_DSR_PDAN             NaN       NaN       NaN       NaN        NaN   \n",
       "VC_DSR_MTMN             NaN       NaN       NaN       NaN        NaN   \n",
       "Temperature       -0.269217  0.759637 -0.817939   -1.4181 -0.0977411   \n",
       "\n",
       "                        2005       2006       2007       2008       2009  \\\n",
       "EG.CFT.ACCS.ZS     -0.383345  -0.187661  0.0436016   0.271899   0.445346   \n",
       "EG.ELC.ACCS.ZS     -0.278292 -0.0359662  0.0550422    0.22844   0.427962   \n",
       "EG.ELC.ACCS.RU.ZS  -0.115794 -0.0375374   0.120318   0.228841   0.390013   \n",
       "EG.ELC.ACCS.UR.ZS   -1.01097  0.0515443  -0.220238    0.26787    0.64741   \n",
       "FX.OWN.TOTL.ZS           NaN        NaN        NaN        NaN        NaN   \n",
       "...                      ...        ...        ...        ...        ...   \n",
       "VC_DSR_IJILN        0.218066  0.0459777  0.0934706  0.0715321  0.0972415   \n",
       "VC_DSR_MISS          0.26197  -0.173728  -0.368545   0.443892  0.0305282   \n",
       "VC_DSR_PDAN       -0.0123201  -0.137992   0.125617   0.532712    0.24665   \n",
       "VC_DSR_MTMN         0.223389  -0.164796   0.226821   0.454255   0.363411   \n",
       "Temperature        -0.286364  -0.234922  -0.817939  -0.903677  -0.577873   \n",
       "\n",
       "                        2010       2011      2012       2013       2014  \\\n",
       "EG.CFT.ACCS.ZS      0.593592   0.722565  0.827819   0.939003    1.04722   \n",
       "EG.ELC.ACCS.ZS      0.578327   0.524656  0.664812   0.664812   0.664812   \n",
       "EG.ELC.ACCS.RU.ZS    0.52483   0.533782   0.61175    0.61175    0.61175   \n",
       "EG.ELC.ACCS.UR.ZS   0.868316   0.501012  0.950479   0.950479   0.950479   \n",
       "FX.OWN.TOTL.ZS           NaN    -1.4133       NaN        NaN   0.750709   \n",
       "...                      ...        ...       ...        ...        ...   \n",
       "VC_DSR_IJILN      -0.0863218  0.0725582 -0.486512   0.506427  -0.379104   \n",
       "VC_DSR_MISS         0.535167  -0.396507 -0.539175   0.301976   0.162293   \n",
       "VC_DSR_PDAN         0.195105  -0.662353 -0.202968  -0.153398  0.0201452   \n",
       "VC_DSR_MTMN         0.476196   0.275943 -0.268863  -0.203482  -0.434208   \n",
       "Temperature          2.42295   -1.70961    0.3138 -0.0291509   0.399538   \n",
       "\n",
       "                        2015       2016       2017      2018      2019  \n",
       "EG.CFT.ACCS.ZS       1.14506    1.21029        NaN       NaN       NaN  \n",
       "EG.ELC.ACCS.ZS      0.664812   0.664812   0.664812  0.664812       NaN  \n",
       "EG.ELC.ACCS.RU.ZS    0.61175    0.61175    0.61175   0.61175       NaN  \n",
       "EG.ELC.ACCS.UR.ZS   0.950479   0.950479   0.950479  0.950479       NaN  \n",
       "FX.OWN.TOTL.ZS           NaN        NaN    0.66259       NaN       NaN  \n",
       "...                      ...        ...        ...       ...       ...  \n",
       "VC_DSR_IJILN      -0.0756324   0.229081   0.126788 -0.541503  0.587335  \n",
       "VC_DSR_MISS        -0.166876  -0.732992   0.382556  0.358528  0.155445  \n",
       "VC_DSR_PDAN        -0.393525 -0.0856296   0.373876  0.285248 -0.296163  \n",
       "VC_DSR_MTMN        -0.160559  -0.270496  0.0929166 -0.401371 -0.599375  \n",
       "Temperature         0.725342   -0.45784 -0.0120033   1.94282   1.06829  \n",
       "\n",
       "[401 rows x 20 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check \n",
    "dict_all_t['Azerbaijan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT\n",
    "indicators_values_i_up = pickle.load(open('utils/data/indicators_values_i_up_wb.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making all time-series \"pointing\" upwards when they are meant to increase\n",
    "\n",
    "indicators_values_i_up = {}\n",
    "\n",
    "for country in countries:\n",
    "    indicators_values_i_up[country] = pd.DataFrame(index=list(dict_all_t[country].index), columns=period)\n",
    "    #dict_all_t[country].drop(columns=['1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999'], inplace=True)\n",
    "    \n",
    "    for seriescode in list(dict_all_t['France'].index):\n",
    "        indicators_values_i_up[country].at[seriescode] = list(np.multiply(list(dict_all_t[country].loc[seriescode]), int(info.loc[info[0] == seriescode][5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000          NaN\n",
       "2001          NaN\n",
       "2002    0.0832496\n",
       "2003          NaN\n",
       "2004          NaN\n",
       "2005          NaN\n",
       "2006          NaN\n",
       "2007    -0.331485\n",
       "2008          NaN\n",
       "2009          NaN\n",
       "2010          NaN\n",
       "2011          NaN\n",
       "2012    -0.688701\n",
       "2013          NaN\n",
       "2014    -0.688701\n",
       "2015          NaN\n",
       "2016          NaN\n",
       "2017          NaN\n",
       "2018          NaN\n",
       "2019          NaN\n",
       "Name: ER.H2O.FWTL.ZS, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check \n",
    "dict_all_i['France'].loc['ER.H2O.FWTL.ZS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000          NaN\n",
       "2001          NaN\n",
       "2002   -0.0832496\n",
       "2003          NaN\n",
       "2004          NaN\n",
       "2005          NaN\n",
       "2006          NaN\n",
       "2007     0.331485\n",
       "2008          NaN\n",
       "2009          NaN\n",
       "2010          NaN\n",
       "2011          NaN\n",
       "2012     0.688701\n",
       "2013          NaN\n",
       "2014     0.688701\n",
       "2015          NaN\n",
       "2016          NaN\n",
       "2017          NaN\n",
       "2018          NaN\n",
       "2019          NaN\n",
       "Name: ER.H2O.FWTL.ZS, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "indicators_values_i_up['France'].loc['ER.H2O.FWTL.ZS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better save these precious data\n",
    "ind_val_i = open('utils/data/indicators_values_i_up_wb.pkl', 'wb')\n",
    "pickle.dump(indicators_values_i_up, ind_val_i)\n",
    "ind_val_i.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining dictionaries for targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = list(info[4].unique())\n",
    "\n",
    "dict_targets = {}\n",
    "\n",
    "for target in targets:\n",
    "    t = info[0].where(info[4] == target)\n",
    "\n",
    "    dict_targets[target] = [i for i in t if str(i) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EN.CLC.MDAT.ZS',\n",
       " 'SG_DSR_SILN',\n",
       " 'SG_DSR_SILS',\n",
       " 'SG_GOV_LOGV',\n",
       " 'VC_DSR_AFFCT',\n",
       " 'VC_DSR_DAFF',\n",
       " 'VC_DSR_IJILN',\n",
       " 'VC_DSR_MISS',\n",
       " 'VC_DSR_MORT',\n",
       " 'VC_DSR_MTMN',\n",
       " 'VC_DSR_MTMP',\n",
       " 'VC_DSR_PDAN',\n",
       " 'VC_DSR_PDLN',\n",
       " 'VC_DSR_PDYN']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "dict_targets['13.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EG.CFT.ACCS.ZS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.ZS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.RU.ZS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG.ELC.ACCS.UR.ZS</th>\n",
       "      <td>0.435264</td>\n",
       "      <td>-0.12284</td>\n",
       "      <td>-0.873248</td>\n",
       "      <td>-1.51735</td>\n",
       "      <td>-1.94323</td>\n",
       "      <td>-2.08537</td>\n",
       "      <td>-1.97205</td>\n",
       "      <td>-1.65538</td>\n",
       "      <td>-1.1873</td>\n",
       "      <td>-0.619743</td>\n",
       "      <td>-0.0299162</td>\n",
       "      <td>0.434609</td>\n",
       "      <td>0.695226</td>\n",
       "      <td>0.779821</td>\n",
       "      <td>0.791425</td>\n",
       "      <td>0.791425</td>\n",
       "      <td>0.791425</td>\n",
       "      <td>0.791425</td>\n",
       "      <td>0.791425</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FX.OWN.TOTL.ZS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.31145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_IJILN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.161676</td>\n",
       "      <td>-0.0539268</td>\n",
       "      <td>-0.115609</td>\n",
       "      <td>-0.0697391</td>\n",
       "      <td>-0.0860881</td>\n",
       "      <td>0.135628</td>\n",
       "      <td>-0.05439</td>\n",
       "      <td>0.452766</td>\n",
       "      <td>-0.544774</td>\n",
       "      <td>0.400793</td>\n",
       "      <td>0.0930136</td>\n",
       "      <td>-0.231236</td>\n",
       "      <td>-0.110639</td>\n",
       "      <td>0.559568</td>\n",
       "      <td>-0.465688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_MISS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.293307</td>\n",
       "      <td>0.157602</td>\n",
       "      <td>0.362193</td>\n",
       "      <td>-0.39217</td>\n",
       "      <td>-0.0763592</td>\n",
       "      <td>-0.547678</td>\n",
       "      <td>0.367566</td>\n",
       "      <td>0.502985</td>\n",
       "      <td>-0.381995</td>\n",
       "      <td>-0.162429</td>\n",
       "      <td>0.149643</td>\n",
       "      <td>0.721109</td>\n",
       "      <td>-0.375511</td>\n",
       "      <td>-0.471343</td>\n",
       "      <td>-0.0467112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_PDAN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00828375</td>\n",
       "      <td>0.123482</td>\n",
       "      <td>-0.0953402</td>\n",
       "      <td>-0.550379</td>\n",
       "      <td>-0.211823</td>\n",
       "      <td>-0.220067</td>\n",
       "      <td>0.627515</td>\n",
       "      <td>0.194197</td>\n",
       "      <td>0.168597</td>\n",
       "      <td>0.00293743</td>\n",
       "      <td>0.413155</td>\n",
       "      <td>0.107903</td>\n",
       "      <td>-0.398803</td>\n",
       "      <td>-0.315469</td>\n",
       "      <td>0.234792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC_DSR_MTMN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.217296</td>\n",
       "      <td>0.142057</td>\n",
       "      <td>-0.231721</td>\n",
       "      <td>-0.445918</td>\n",
       "      <td>-0.298082</td>\n",
       "      <td>-0.525782</td>\n",
       "      <td>-0.288942</td>\n",
       "      <td>0.25889</td>\n",
       "      <td>0.225174</td>\n",
       "      <td>0.438844</td>\n",
       "      <td>0.156262</td>\n",
       "      <td>0.296622</td>\n",
       "      <td>-0.0700858</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.418461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature</th>\n",
       "      <td>-0.634326</td>\n",
       "      <td>0.954974</td>\n",
       "      <td>-0.0348531</td>\n",
       "      <td>0.425207</td>\n",
       "      <td>0.927092</td>\n",
       "      <td>0.801621</td>\n",
       "      <td>-0.146383</td>\n",
       "      <td>-0.634326</td>\n",
       "      <td>-0.132442</td>\n",
       "      <td>0.383384</td>\n",
       "      <td>2.6558</td>\n",
       "      <td>-0.397325</td>\n",
       "      <td>0.536737</td>\n",
       "      <td>1.17803</td>\n",
       "      <td>-1.54051</td>\n",
       "      <td>-0.899209</td>\n",
       "      <td>-0.271854</td>\n",
       "      <td>-0.285795</td>\n",
       "      <td>-1.55445</td>\n",
       "      <td>-1.33139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       2000      2001       2002      2003      2004  \\\n",
       "EG.CFT.ACCS.ZS            0         0          0         0         0   \n",
       "EG.ELC.ACCS.ZS            0         0          0         0         0   \n",
       "EG.ELC.ACCS.RU.ZS         0         0          0         0         0   \n",
       "EG.ELC.ACCS.UR.ZS  0.435264  -0.12284  -0.873248  -1.51735  -1.94323   \n",
       "FX.OWN.TOTL.ZS          NaN       NaN        NaN       NaN       NaN   \n",
       "...                     ...       ...        ...       ...       ...   \n",
       "VC_DSR_IJILN            NaN       NaN        NaN       NaN       NaN   \n",
       "VC_DSR_MISS             NaN       NaN        NaN       NaN       NaN   \n",
       "VC_DSR_PDAN             NaN       NaN        NaN       NaN       NaN   \n",
       "VC_DSR_MTMN             NaN       NaN        NaN       NaN       NaN   \n",
       "Temperature       -0.634326  0.954974 -0.0348531  0.425207  0.927092   \n",
       "\n",
       "                         2005       2006       2007       2008       2009  \\\n",
       "EG.CFT.ACCS.ZS              0          0          0          0          0   \n",
       "EG.ELC.ACCS.ZS              0          0          0          0          0   \n",
       "EG.ELC.ACCS.RU.ZS           0          0          0          0          0   \n",
       "EG.ELC.ACCS.UR.ZS    -2.08537   -1.97205   -1.65538    -1.1873  -0.619743   \n",
       "FX.OWN.TOTL.ZS            NaN        NaN        NaN        NaN        NaN   \n",
       "...                       ...        ...        ...        ...        ...   \n",
       "VC_DSR_IJILN        -0.161676 -0.0539268  -0.115609 -0.0697391 -0.0860881   \n",
       "VC_DSR_MISS         -0.293307   0.157602   0.362193   -0.39217 -0.0763592   \n",
       "VC_DSR_PDAN        0.00828375   0.123482 -0.0953402  -0.550379  -0.211823   \n",
       "VC_DSR_MTMN         -0.217296   0.142057  -0.231721  -0.445918  -0.298082   \n",
       "Temperature          0.801621  -0.146383  -0.634326  -0.132442   0.383384   \n",
       "\n",
       "                        2010      2011      2012      2013        2014  \\\n",
       "EG.CFT.ACCS.ZS             0         0         0         0           0   \n",
       "EG.ELC.ACCS.ZS             0         0         0         0           0   \n",
       "EG.ELC.ACCS.RU.ZS          0         0         0         0           0   \n",
       "EG.ELC.ACCS.UR.ZS -0.0299162  0.434609  0.695226  0.779821    0.791425   \n",
       "FX.OWN.TOTL.ZS           NaN  -1.31145       NaN       NaN      0.1974   \n",
       "...                      ...       ...       ...       ...         ...   \n",
       "VC_DSR_IJILN        0.135628  -0.05439  0.452766 -0.544774    0.400793   \n",
       "VC_DSR_MISS        -0.547678  0.367566  0.502985 -0.381995   -0.162429   \n",
       "VC_DSR_PDAN        -0.220067  0.627515  0.194197  0.168597  0.00293743   \n",
       "VC_DSR_MTMN        -0.525782 -0.288942   0.25889  0.225174    0.438844   \n",
       "Temperature           2.6558 -0.397325  0.536737   1.17803    -1.54051   \n",
       "\n",
       "                        2015      2016       2017      2018       2019  \n",
       "EG.CFT.ACCS.ZS             0         0        NaN       NaN        NaN  \n",
       "EG.ELC.ACCS.ZS             0         0          0         0        NaN  \n",
       "EG.ELC.ACCS.RU.ZS          0         0          0         0        NaN  \n",
       "EG.ELC.ACCS.UR.ZS   0.791425  0.791425   0.791425  0.791425        NaN  \n",
       "FX.OWN.TOTL.ZS           NaN       NaN    1.11406       NaN        NaN  \n",
       "...                      ...       ...        ...       ...        ...  \n",
       "VC_DSR_IJILN       0.0930136 -0.231236  -0.110639  0.559568  -0.465688  \n",
       "VC_DSR_MISS         0.149643  0.721109  -0.375511 -0.471343 -0.0467112  \n",
       "VC_DSR_PDAN         0.413155  0.107903  -0.398803 -0.315469   0.234792  \n",
       "VC_DSR_MTMN         0.156262  0.296622 -0.0700858  0.354839   0.418461  \n",
       "Temperature        -0.899209 -0.271854  -0.285795  -1.55445   -1.33139  \n",
       "\n",
       "[401 rows x 20 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicators_values_i_up['Germany']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b90e541831841f9b070bad76bd205ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=182.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "targets_values_i_up = {}\n",
    "targets_values_i_up_arr = {}\n",
    "targets_values_i_up_avg = {}\n",
    "\n",
    "for country in tqdm(countries):\n",
    "    targets_values_i_up_arr[country] = []\n",
    "    targets_values_i_up_avg[country] = pd.DataFrame(index=targets, columns=period)\n",
    "    \n",
    "    for t, target in enumerate(list(dict_targets.keys())):\n",
    "        list_indicators_values_i_up_arr = []\n",
    "\n",
    "        for y, year in enumerate(period):\n",
    "            list_indicators_values_i_up_avg = []\n",
    "            for i, indicator in enumerate(list(dict_targets[target])):\n",
    "                # do not append NaNs                  \n",
    "                if np.isnan(indicators_values_i_up[country].loc[indicator, year])==False:\n",
    "                    list_indicators_values_i_up_arr.append(indicators_values_i_up[country].loc[indicator, year])\n",
    "                    list_indicators_values_i_up_avg.append(indicators_values_i_up[country].loc[indicator, year])\n",
    "            \n",
    "            # 1. averaging\n",
    "            targets_values_i_up_avg[country].loc[target, year] = np.mean(list_indicators_values_i_up_avg)\n",
    "\n",
    "        # 2. concatenating\n",
    "        targets_values_i_up_arr[country].append(list_indicators_values_i_up_arr)\n",
    "    \n",
    "    targets_values_i_up[country] = pd.DataFrame(data=targets_values_i_up_arr[country], index=list(dict_targets.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72014986929773\n",
      "0.72014986929773\n"
     ]
    }
   ],
   "source": [
    "# check whether averages were correctly computed\n",
    "print(targets_values_i_up_avg['France'].loc['2.1', '2017'])\n",
    "print(np.mean(indicators_values_i_up['France'].loc[info[info[4]=='2.1'][0]]['2017']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 282\n",
      "1.1 19\n",
      "1.2 92\n",
      "2.3 18\n",
      "2.2 317\n",
      "2.1 43\n",
      "3.5 6\n",
      "3.3 133\n",
      "3.2 46\n",
      "3.4 30\n",
      "3.7 38\n",
      "3.8 76\n",
      "3.c 38\n",
      "3.a 18\n",
      "3.9 19\n",
      "3.1 37\n",
      "3.6 2\n",
      "4.6 133\n",
      "4.1 420\n",
      "4.5 80\n",
      "4.2 80\n",
      "4.c 420\n",
      "4.4 376\n",
      "4.3 60\n",
      "5.5 69\n",
      "5.6 13\n",
      "5.1 25\n",
      "5.4 76\n",
      "5.2 14\n",
      "5.3 57\n",
      "6.4 97\n",
      "6.1 108\n",
      "6.2 216\n",
      "7.1 74\n",
      "7.3 16\n",
      "7.2 32\n",
      "8.1 82\n",
      "8.3 73\n",
      "8.2 260\n",
      "8.5 300\n",
      "8.7 51\n",
      "8.6 60\n",
      "9.4 68\n",
      "9.5 38\n",
      "9.1 76\n",
      "9.2 40\n",
      "9.b 18\n",
      "10.b 38\n",
      "10.2 19\n",
      "10.c 14\n",
      "10.1 8\n",
      "11.6 50\n",
      "11.1 65\n",
      "12.2 127\n",
      "13.2 1\n",
      "13.1 166\n",
      "14.4 51\n",
      "14.5 3\n",
      "15.1 40\n",
      "15.5 4\n",
      "16.6 16\n",
      "16.5 32\n",
      "16.9 89\n",
      "16.1 73\n",
      "17.3 60\n",
      "17.2 38\n",
      "17.4 19\n",
      "17.1 40\n",
      "17.17 60\n",
      "17.6 38\n",
      "17.19 48\n",
      "17.18 16\n",
      "17.8 19\n",
      "17.11 20\n",
      "17.13 520\n",
      "17.12 114\n",
      "T 20\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "for t, target in enumerate(targets):\n",
    "    print(target, len(targets_values_i_up_arr['Azerbaijan'][t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better save these precious data\n",
    "tar_val_i_up = open('utils/data/targets_values_i_up_wb.pkl', 'wb')\n",
    "pickle.dump(targets_values_i_up, tar_val_i_up)\n",
    "tar_val_i_up.close()\n",
    "\n",
    "tar_val_i_up_arr = open('utils/data/targets_values_i_up_arr_wb.pkl', 'wb')\n",
    "pickle.dump(targets_values_i_up_arr, tar_val_i_up_arr)\n",
    "tar_val_i_up_arr.close()\n",
    "\n",
    "tar_val_i_up_avg = open('utils/data/targets_values_i_up_avg_wb.pkl', 'wb')\n",
    "pickle.dump(targets_values_i_up_avg, tar_val_i_up_avg)\n",
    "tar_val_i_up_avg.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *(WorldBank data set)* Concatenating target data to goal-level\n",
    "\n",
    "Defining dictionaries for goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals = list(info[3].unique())\n",
    "\n",
    "dict_goals = {}\n",
    "\n",
    "for goal in goals:\n",
    "    g = info[4].where(info[3] == goal)\n",
    "\n",
    "    dict_goals[goal] = [t for t in g if str(t) != 'nan']\n",
    "    dict_goals[goal] = list(set(dict_goals[goal]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.3', '1.1', '1.2']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "dict_goals['1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating:\n",
    "\n",
    "Recall that we define our dimensionality as $d \\times T$, and countries are independent samples. We do this in the next cell exemplarily by appending the years for all indicators of SDG 1 to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example with SDG 1\n",
    "len([x for x in list(targets_values_i_up[country].loc['1.1']) if str(x) != 'nan']) + len([x for x in list(targets_values_i_up[country].loc['1.2']) if str(x) != 'nan']) + len([x for x in list(targets_values_i_up[country].loc['1.3']) if str(x) != 'nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033bc3062b6a48369112b240ccc86689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=182.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "goals_values_i_up = {}\n",
    "goals_values_i_up_arr = {}\n",
    "goals_values_i_up_avg = {}\n",
    "\n",
    "for country in tqdm(countries):\n",
    "    goals_values_i_up_arr[country] = []\n",
    "    goals_values_i_up_avg[country] = []   # define this list with target values being averages over indicators\n",
    "    \n",
    "    for g, goal in enumerate(list(dict_goals.keys())):\n",
    "        list_targets_values_i_up = []\n",
    "        list_targets_values_i_up_avg = []\n",
    "\n",
    "        for t in dict_goals[goal]:   # do not append NaN's\n",
    "            list_targets_values_i_up.extend([x for x in list(targets_values_i_up[country].loc[t]) if np.isnan(x)==False])\n",
    "            list_targets_values_i_up_avg.extend([x for x in list(targets_values_i_up_avg[country].loc[t]) if np.isnan(x)==False])\n",
    "            \n",
    "        # 1. append target averages\n",
    "        goals_values_i_up_avg[country].append(np.asarray(list_targets_values_i_up_avg))\n",
    "\n",
    "        # 2. concatenating\n",
    "        goals_values_i_up_arr[country].append(np.asarray(list_targets_values_i_up))\n",
    "    \n",
    "    goals_values_i_up_avg[country] = np.asarray(goals_values_i_up_avg[country])\n",
    "    goals_values_i_up[country] = pd.DataFrame(data=goals_values_i_up_arr[country], index=list(dict_goals.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating target averages\n",
    "goals_values_i_up_avg['France'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 56\n",
      "2 57\n",
      "3 137\n",
      "4 138\n",
      "5 106\n",
      "6 53\n",
      "7 51\n",
      "8 117\n",
      "9 93\n",
      "10 49\n",
      "11 30\n",
      "12 19\n",
      "13 16\n",
      "14 20\n",
      "15 20\n",
      "16 72\n",
      "17 227\n",
      "T 20\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "for g, goal in enumerate(list(dict_goals.keys())):\n",
    "    print(goal, len(goals_values_i_up_avg['France'][g]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage from saving these numbers in arrays and not dataframes should be clear now: in arrays we only save the actual numbers, but dataframes have a fixed number of columns, hence add NaN's to the goals which do not have data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better save these precious data\n",
    "goa_val_i_up = open('utils/data/goals_values_i_up_wb.pkl', 'wb')\n",
    "pickle.dump(goals_values_i_up, goa_val_i_up)\n",
    "goa_val_i_up.close()\n",
    "\n",
    "goa_val_i_up_arr = open('utils/data/goals_values_i_up_arr_wb.pkl', 'wb')\n",
    "pickle.dump(goals_values_i_up_arr, goa_val_i_up_arr)\n",
    "goa_val_i_up_arr.close()\n",
    "\n",
    "goa_val_i_up_avg = open('utils/data/goals_values_i_up_avg_wb.pkl', 'wb')\n",
    "pickle.dump(goals_values_i_up_avg, goa_val_i_up_avg)\n",
    "goa_val_i_up_avg.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 - Spark (local)",
   "language": "python",
   "name": "spark-3-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
